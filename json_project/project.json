"{\"properties\": [{\"name\": \"script221.ipynb\"}], \"defaultBranch\": [1], \"files\": [null], \"modules\": [{\"1\": {\"id\": 1, \"state\": [4], \"command\": [{\"id\": [1], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# import time\\nimport time\\nt1 = time.time()\"}]], \"revisionId\": [[null]], \"properties\": []}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091117\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091117\"}}, \"2\": {\"id\": 2, \"state\": [4], \"command\": [{\"id\": [2], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"import math\\nimport random\\nimport pandas as pd\\nimport numpy as np\\nimport cv2\\nfrom sklearn.preprocessing import MinMaxScaler\\nimport matplotlib\\nfrom matplotlib import pyplot as plt\\n \"}]], \"revisionId\": [[null]], \"properties\": []}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091152\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091152\"}}, \"3\": {\"id\": 3, \"state\": [4], \"command\": [{\"id\": [3], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# np_rand_seed = random.randint(0,100)\\n# tf_rand_seed = random.randint(0,100)\\nnp_rand_seed = 97\\ntf_rand_seed = 82\\nnp.random.seed(np_rand_seed)\"}]], \"revisionId\": [[null]], \"properties\": [\"np\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091173\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091173\"}}, \"4\": {\"id\": 4, \"state\": [4], \"command\": [{\"id\": [4], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"data = pd.read_json('../input/train.json')\\ntest_data = pd.read_json('../input/test.json')\"}]], \"revisionId\": [[null]], \"properties\": [\"pd\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091192\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091192\"}}, \"5\": {\"id\": 5, \"state\": [4], \"command\": [{\"id\": [5], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"data.head(5)\"}]], \"revisionId\": [[null]], \"properties\": [\"data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091209\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091209\"}}, \"6\": {\"id\": 6, \"state\": [4], \"command\": [{\"id\": [6], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"test_data.head(5)\"}]], \"revisionId\": [[null]], \"properties\": [\"test_data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091227\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091227\"}}, \"7\": {\"id\": 7, \"state\": [4], \"command\": [{\"id\": [7], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"print(\\\"Shape of train set:\\\", data.shape)\\nprint(\\\"Shape of test set:\\\", test_data.shape)\"}]], \"revisionId\": [[null]], \"properties\": [\"data\", \"test_data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091245\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091245\"}}, \"8\": {\"id\": 8, \"state\": [4], \"command\": [{\"id\": [8], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"print(\\\"Shape of band 1:\\\",  np.shape(data.band_1.iloc[0]))\\nprint(\\\"Shape of band 2:\\\",  np.shape(data.band_2.iloc[0]))\"}]], \"revisionId\": [[null]], \"properties\": [\"np\", \"data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091262\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091262\"}}, \"9\": {\"id\": 9, \"state\": [4], \"command\": [{\"id\": [9], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"print(\\\"Type of band 1:\\\",  type(data.band_1.iloc[0]))\\nprint(\\\"Type of band 2:\\\",  type(data.band_2.iloc[0]))\"}]], \"revisionId\": [[null]], \"properties\": [\"data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091279\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091279\"}}, \"10\": {\"id\": 10, \"state\": [4], \"command\": [{\"id\": [10], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"data[data['inc_angle']=='na'] = data[data['inc_angle']!='na']['inc_angle'].mean()\"}]], \"revisionId\": [[null]], \"properties\": [\"data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091300\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091300\"}}, \"11\": {\"id\": 11, \"state\": [4], \"command\": [{\"id\": [11], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"data['inc_angle'] = data['inc_angle'].apply(lambda x: math.radians(x))\"}]], \"revisionId\": [[null]], \"properties\": [\"data\", \"math\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091318\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091318\"}}, \"12\": {\"id\": 12, \"state\": [4], \"command\": [{\"id\": [12], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"data.inc_angle.head()\"}]], \"revisionId\": [[null]], \"properties\": [\"data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091336\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091336\"}}, \"13\": {\"id\": 13, \"state\": [4], \"command\": [{\"id\": [13], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def find_missing_data(series, shape):\\n    \\n    '''function which return the count and the index of mismatched data'''    \\n    count = 0\\n    missing_list = []\\n    for i,x in enumerate(series):   \\n        if np.shape(series.iloc[i]) != shape:\\n            missing_list.append(i)\\n            count += 1\\n            \\n    return missing_list, count\"}]], \"revisionId\": [[null]], \"properties\": [\"np\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091356\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091356\"}}, \"14\": {\"id\": 14, \"state\": [4], \"command\": [{\"id\": [14], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"missing_list1, count1 = find_missing_data(data.band_1, (5625,))\\nprint(\\\"count: \\\", count1)\\nprint(\\\"missing data: \\\", missing_list1)\"}]], \"revisionId\": [[null]], \"properties\": [\"find_missing_data\", \"data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091374\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091374\"}}, \"15\": {\"id\": 15, \"state\": [4], \"command\": [{\"id\": [15], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"missing_list2, count2 = find_missing_data(data.band_2, (5625,))\\nprint(\\\"count: \\\", count1)\\nprint(\\\"missing data: \\\", missing_list2)\"}]], \"revisionId\": [[null]], \"properties\": [\"find_missing_data\", \"data\", \"count1\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091392\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091392\"}}, \"16\": {\"id\": 16, \"state\": [4], \"command\": [{\"id\": [16], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"missing_list1 == missing_list2\"}]], \"revisionId\": [[null]], \"properties\": [\"missing_list1\", \"missing_list2\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091411\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091411\"}}, \"17\": {\"id\": 17, \"state\": [4], \"command\": [{\"id\": [17], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def drop_data(df, index):\\n    \\n    '''function to drop data by index'''\\n    return df.drop(df.index[index])\"}]], \"revisionId\": [[null]], \"properties\": []}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091429\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091429\"}}, \"18\": {\"id\": 18, \"state\": [4], \"command\": [{\"id\": [18], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"data = drop_data(data, missing_list1)\"}]], \"revisionId\": [[null]], \"properties\": [\"drop_data\", \"missing_list1\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091446\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091446\"}}, \"19\": {\"id\": 19, \"state\": [4], \"command\": [{\"id\": [19], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"data.shape\"}]], \"revisionId\": [[null]], \"properties\": [\"data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091463\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091463\"}}, \"20\": {\"id\": 20, \"state\": [4], \"command\": [{\"id\": [20], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"print(\\\"Number of positive classes: \\\", len(data[data['is_iceberg'] == 1.0]))\\nprint(\\\"Number of negative classes: \\\", len(data[data['is_iceberg'] == 0.0]))\"}]], \"revisionId\": [[null]], \"properties\": [\"data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091480\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091480\"}}, \"21\": {\"id\": 21, \"state\": [4], \"command\": [{\"id\": [21], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def standardise_vector(vector):\\n    '''standardise vector'''\\n    standardised_vector = (np.array(vector) - np.mean(vector)) / np.std(vector)\\n    return standardised_vector.tolist()\"}]], \"revisionId\": [[null]], \"properties\": [\"np\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091499\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091499\"}}, \"22\": {\"id\": 22, \"state\": [4], \"command\": [{\"id\": [22], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def mean_normalise_vector(vector):\\n    '''mean normalize vector'''\\n    normalised_vector = (np.array(vector) - np.mean(vector)) / (np.max(vector) - np.min(vector))\\n    return normalised_vector.tolist()\"}]], \"revisionId\": [[null]], \"properties\": [\"np\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091516\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091516\"}}, \"23\": {\"id\": 23, \"state\": [4], \"command\": [{\"id\": [23], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def min_max_scaler(vector, minimum = 0, maximum = 1):\\n    '''minmaxscaler'''\\n    X_std  = (np.array(vector) - np.min(vector)) / (np.max(vector) - np.min(vector))\\n    scaled_vector = X_std * (maximum - minimum) + minimum\\n    return scaled_vector.tolist()\"}]], \"revisionId\": [[null]], \"properties\": [\"np\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091534\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091534\"}}, \"24\": {\"id\": 24, \"state\": [4], \"command\": [{\"id\": [24], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"data['band_1'] = data['band_1'].apply(standardise_vector)\\ndata['band_2'] = data['band_2'].apply(standardise_vector)\"}]], \"revisionId\": [[null]], \"properties\": [\"data\", \"standardise_vector\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091553\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091553\"}}, \"25\": {\"id\": 25, \"state\": [4], \"command\": [{\"id\": [25], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"data.head(5)\"}]], \"revisionId\": [[null]], \"properties\": [\"data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091570\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091570\"}}, \"26\": {\"id\": 26, \"state\": [4], \"command\": [{\"id\": [26], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"band_1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in data[\\\"band_1\\\"]])\\nband_2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in data[\\\"band_2\\\"]])\"}]], \"revisionId\": [[null]], \"properties\": [\"np\", \"data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091589\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091589\"}}, \"27\": {\"id\": 27, \"state\": [4], \"command\": [{\"id\": [27], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"print(\\\"Shape of band 1 image:\\\",band_1.shape)\\nprint(\\\"Shape of band 2 image:\\\",band_2.shape)\"}]], \"revisionId\": [[null]], \"properties\": [\"band_1\", \"band_2\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091606\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091606\"}}, \"28\": {\"id\": 28, \"state\": [4], \"command\": [{\"id\": [28], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"test_data['inc_angle'] = test_data['inc_angle'].apply(lambda x: math.radians(x))\"}]], \"revisionId\": [[null]], \"properties\": [\"test_data\", \"math\", \"x\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091625\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091625\"}}, \"29\": {\"id\": 29, \"state\": [4], \"command\": [{\"id\": [29], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"test_data.inc_angle.head()\"}]], \"revisionId\": [[null]], \"properties\": [\"test_data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091643\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091643\"}}, \"30\": {\"id\": 30, \"state\": [4], \"command\": [{\"id\": [30], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"missing_list3, count3 = find_missing_data(test_data.band_1, (5625,))\\nprint(\\\"count: \\\", count3)\\nprint(\\\"missing data: \\\", missing_list3)\"}]], \"revisionId\": [[null]], \"properties\": [\"find_missing_data\", \"test_data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091660\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091660\"}}, \"31\": {\"id\": 31, \"state\": [4], \"command\": [{\"id\": [31], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"missing_list4, count4 = find_missing_data(test_data.band_2, (5625,))\\nprint(\\\"count: \\\", count4)\\nprint(\\\"missing data: \\\", missing_list4)\"}]], \"revisionId\": [[null]], \"properties\": [\"find_missing_data\", \"test_data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091677\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091677\"}}, \"32\": {\"id\": 32, \"state\": [4], \"command\": [{\"id\": [32], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"test_data['band_1'] = test_data['band_1'].apply(standardise_vector)\\ntest_data['band_2'] = test_data['band_2'].apply(standardise_vector)\"}]], \"revisionId\": [[null]], \"properties\": [\"test_data\", \"standardise_vector\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091695\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091695\"}}, \"33\": {\"id\": 33, \"state\": [4], \"command\": [{\"id\": [33], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"band_1_test = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test_data[\\\"band_1\\\"]])\\nband_2_test = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test_data[\\\"band_2\\\"]])\"}]], \"revisionId\": [[null]], \"properties\": [\"np\", \"test_data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091712\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091712\"}}, \"34\": {\"id\": 34, \"state\": [4], \"command\": [{\"id\": [34], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"print(\\\"Shape of test set band 1 image:\\\",band_1_test.shape)\\nprint(\\\"Shape of test set band 2 image:\\\",band_2_test.shape)\"}]], \"revisionId\": [[null]], \"properties\": [\"band_1_test\", \"band_2_test\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091729\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091729\"}}, \"35\": {\"id\": 35, \"state\": [4], \"command\": [{\"id\": [35], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"labels = data.is_iceberg.as_matrix()\\nangles = data.inc_angle.as_matrix()\"}]], \"revisionId\": [[null]], \"properties\": [\"data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091749\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091749\"}}, \"36\": {\"id\": 36, \"state\": [4], \"command\": [{\"id\": [36], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# randomly choosing the train and validation indices\\ntrain_indices = np.random.choice(len(labels), round(len(labels)*0.75), replace=False)\\nvalidation_indices = np.array(list(set(range(len(labels))) - set(train_indices)))\\n\\n# extract train set\\nband_1_train = band_1[train_indices]\\nband_2_train = band_2[train_indices]\\nangles_train = angles[train_indices]\\nlabels_train = labels[train_indices]\\n\\n# extract validation set\\nband_1_validation = band_1[validation_indices]\\nband_2_validation = band_2[validation_indices]\\nangles_validation = angles[validation_indices]\\nlabels_validation = labels[validation_indices]\\n\\n# extract test set\\nband_1_test = band_1_test\\nband_2_test = band_2_test\\nangles_test = test_data.inc_angle.as_matrix()\\niD = test_data.id.as_matrix()\"}]], \"revisionId\": [[null]], \"properties\": [\"np\", \"labels\", \"band_1\", \"band_2\", \"angles\", \"test_data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091767\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091767\"}}, \"37\": {\"id\": 37, \"state\": [4], \"command\": [{\"id\": [37], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"band_1_train = band_1_train.astype(np.float32)\\nband_1_validation = band_1_validation.astype(np.float32)\\nband_1_test = band_1_test.astype(np.float32)\\nband_2_train = band_2_train.astype(np.float32)\\nband_2_validation = band_2_validation.astype(np.float32)\\nband_2_test = band_2_test.astype(np.float32)\\nangles_train = angles_train.astype(np.float32)\\nangles_validation = angles_validation.astype(np.float32)\\nangles_test = angles_test.astype(np.float32)\\nlabels_train = labels_train.astype(np.float32)\\nlabels_validation = labels_validation.astype(np.float32)\\niD = iD.astype(np.str)\"}]], \"revisionId\": [[null]], \"properties\": [\"np\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091785\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091785\"}}, \"38\": {\"id\": 38, \"state\": [4], \"command\": [{\"id\": [38], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# delete the unnecessary variables out of memory\\ndel(data, test_data, band_1, band_2)\"}]], \"revisionId\": [[null]], \"properties\": []}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091802\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091802\"}}, \"39\": {\"id\": 39, \"state\": [4], \"command\": [{\"id\": [39], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"print(\\\"Shape of band_1_train:\\\",band_1_train.shape)\\nprint(\\\"Shape of band_2_train:\\\",band_1_train.shape)\\nprint(\\\"Shape of angles_train:\\\",angles_train.shape)\\nprint(\\\"Shape of labels_train:\\\",labels_train.shape)\\nprint(\\\"Shape of band_1_validation:\\\",band_1_validation.shape)\\nprint(\\\"Shape of band_2_validation:\\\",band_2_validation.shape)\\nprint(\\\"Shape of angles_validation:\\\",angles_validation.shape)\\nprint(\\\"Shape of labels_validation:\\\",labels_validation.shape)\\nprint(\\\"Shape of band_1_test:\\\",band_1_test.shape)\\nprint(\\\"Shape of band_2_test:\\\",band_2_test.shape)\\nprint(\\\"Shape of angles_test:\\\",angles_test.shape)\\nprint(\\\"Shape of iD:\\\",iD.shape)\"}]], \"revisionId\": [[null]], \"properties\": [\"band_1_train\", \"angles_train\", \"labels_train\", \"band_1_validation\", \"band_2_validation\", \"angles_validation\", \"labels_validation\", \"band_1_test\", \"band_2_test\", \"angles_test\", \"iD\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091820\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091820\"}}, \"40\": {\"id\": 40, \"state\": [4], \"command\": [{\"id\": [40], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def rotate_image(img, angle = 20):\\n    \\n    '''a function to rotate image by a given degree'''\\n    \\n    # rotate image\\n    original = img.copy()\\n\\n    M_rotate = cv2.getRotationMatrix2D((37,37),angle,1)\\n    img_new = cv2.warpAffine(img,M_rotate,(75,75))\\n    \\n    length_row = 0\\n    length_column = 0\\n    boundary_step = 5\\n    \\n    for i in range(len(img_new)):\\n        if img_new[0,i]!=float(0.0):\\n            length_row = i\\n            break\\n    for i in range(len(img_new)):\\n        if img_new[i,0]!=float(0.0):\\n            length_column = i\\n            break\\n    \\n    # subsitute the padding from original image\\n    img_new[:length_column+boundary_step,:length_row+boundary_step] = \\\\\\n    original[:length_column+boundary_step,:length_row+boundary_step] \\n    img_new[-(length_row+boundary_step):,:length_column+boundary_step] = \\\\\\n    original[-(length_row+boundary_step):,:length_column+boundary_step]\\n    img_new[:length_row+boundary_step,-(length_column+boundary_step):] = \\\\\\n    original[:length_row+boundary_step,-(length_column+boundary_step):]\\n    img_new[-(length_column+boundary_step):,-(length_row+boundary_step):] = \\\\\\n    original[-(length_column+boundary_step):,-(length_row+boundary_step):]\\n    \\n    return img_new\"}]], \"revisionId\": [[null]], \"properties\": [\"cv2\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091841\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091841\"}}, \"41\": {\"id\": 41, \"state\": [4], \"command\": [{\"id\": [41], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def translate_horizontal(image, shift_horizontal = 5):\\n    \\n    '''a function to translate image horizontally by a shift'''\\n    \\n    # horizontally shift image\\n    img = image.copy()\\n    \\n    shift_vertical = 0; \\n    if shift_horizontal<0:\\n        image_slice = img[:,shift_horizontal:].copy()\\n    if shift_horizontal>0:\\n        image_slice = img[:,:shift_horizontal].copy()\\n    M_translate = np.float32([[1,0,shift_horizontal],[0,1,shift_vertical]])\\n    img_new = cv2.warpAffine(img,M_translate,(75,75))\\n    \\n    # subsitute the padding from original image\\n    if shift_horizontal<0:\\n        img_new[:,shift_horizontal:] = image_slice\\n    if shift_horizontal>0:\\n        img_new[:,:shift_horizontal] = image_slice\\n        \\n    return img_new.reshape(75,75).astype(np.float32)\"}]], \"revisionId\": [[null]], \"properties\": [\"np\", \"cv2\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091860\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091860\"}}, \"42\": {\"id\": 42, \"state\": [4], \"command\": [{\"id\": [42], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def translate_vertical(image, shift_vertical = 5):\\n    \\n    '''a function to translate image vertically by a shift'''\\n    \\n    # vertically shift image\\n    img = image.copy()\\n    \\n    shift_horizontal = 0;\\n    if shift_vertical<0:\\n        image_slice = img[shift_vertical:,:].copy()\\n    if shift_vertical>0:\\n        image_slice = img[:shift_vertical,:].copy()\\n    M_translate = np.float32([[1,0,shift_horizontal],[0,1,shift_vertical]])\\n    img_new = cv2.warpAffine(img,M_translate,(75,75))\\n    \\n    # subsitute the padding from original image\\n    if shift_vertical<0:\\n        img_new[shift_vertical:,:] = image_slice\\n    if shift_vertical>0:\\n        img_new[:shift_vertical,:] = image_slice\\n        \\n    return img_new.reshape(75,75).astype(np.float32)\"}]], \"revisionId\": [[null]], \"properties\": [\"np\", \"cv2\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091878\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091878\"}}, \"43\": {\"id\": 43, \"state\": [4], \"command\": [{\"id\": [43], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def translate_positive_diagonal(image, shift_diagonal = 5):\\n    \\n    '''a function to translate image along positive diagonal'''\\n    \\n    # translate image along positive diagonal\\n    img = image.copy()\\n    \\n    if shift_diagonal<0:\\n        hor_slice = img[shift_diagonal:,:].copy()\\n        ver_slice = img[:,shift_diagonal:].copy()\\n    else:\\n        hor_slice = img[:shift_diagonal,:].copy()\\n        ver_slice = img[:,:shift_diagonal].copy()\\n    M_translate = np.float32([[1,0,shift_diagonal],[0,1,shift_diagonal]])\\n    img_new = cv2.warpAffine(img,M_translate,(75,75))\\n    \\n    # subsitute the padding from original image\\n    if shift_diagonal<0:\\n        img_new[shift_diagonal:,:] = hor_slice\\n        img_new[:,shift_diagonal:] = ver_slice\\n    else:\\n        img_new[:shift_diagonal,:] = hor_slice\\n        img_new[:,:shift_diagonal] = ver_slice\\n    \\n    return img_new.reshape(75,75).astype(np.float32)\"}]], \"revisionId\": [[null]], \"properties\": [\"np\", \"cv2\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091897\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091897\"}}, \"44\": {\"id\": 44, \"state\": [4], \"command\": [{\"id\": [44], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def translate_negative_diagonal(image, shift_diagonal = 5):\\n    \\n    '''a function to translate image along negative diagonal'''\\n    \\n    # translate image along negative diagonal\\n    img = image.copy()\\n    \\n    if shift_diagonal<0:\\n        hor_slice = img[:-shift_diagonal,:].copy()\\n        ver_slice = img[:,shift_diagonal:].copy()\\n    if shift_diagonal>0:\\n        hor_slice = img[-shift_diagonal:,:].copy()\\n        ver_slice = img[:,:shift_diagonal].copy()\\n    M_translate = np.float32([[1,0,shift_diagonal],[0,1,-shift_diagonal]])\\n    img_new = cv2.warpAffine(img,M_translate,(75,75))\\n    \\n    # subsitute the padding from original image\\n    if shift_diagonal<0:\\n        img_new[:-shift_diagonal,:] = hor_slice\\n        img_new[:,shift_diagonal:] = ver_slice\\n    if shift_diagonal>0:\\n        img_new[-shift_diagonal:,:] = hor_slice\\n        img_new[:,:shift_diagonal] = ver_slice\\n        \\n    return img_new.reshape(75,75).astype(np.float32)\"}]], \"revisionId\": [[null]], \"properties\": [\"np\", \"cv2\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091917\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091917\"}}, \"45\": {\"id\": 45, \"state\": [4], \"command\": [{\"id\": [45], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def flip(image, direction = 0):\\n    \\n    '''a function to flip image'''\\n    img = image.copy()\\n    return cv2.flip(img,direction)\"}]], \"revisionId\": [[null]], \"properties\": [\"cv2\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091935\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091935\"}}, \"46\": {\"id\": 46, \"state\": [4], \"command\": [{\"id\": [46], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def zoom(image, zoom_shift = 5):\\n    \\n    '''a function to zoom image'''\\n    \\n    # zoom image\\n    img = image.copy()\\n    \\n    # zoom in \\n    if zoom_shift>0:\\n        # scale\\n        img_new = cv2.resize(img, (75+zoom_shift*2,75+zoom_shift*2)) \\n        # crop\\n        img_new = img_new[zoom_shift:-zoom_shift,zoom_shift:-zoom_shift] \\n    # zoom out\\n    else:\\n        zoom_shift *=-1\\n        \\n        hor_top = img[:zoom_shift,:]\\n        hor_bottom =img[-zoom_shift:,:]\\n        ver_left = img[:,:zoom_shift]\\n        ver_right = img[:,-zoom_shift:]\\n        \\n        # scale\\n        img_new = cv2.resize(img, (75-zoom_shift*2,75-zoom_shift*2)) \\n        # zero padding\\n        img_new = cv2.copyMakeBorder(img_new,zoom_shift,zoom_shift,zoom_shift,zoom_shift,\\n                                     cv2.BORDER_CONSTANT,value=0.0)\\n        # subsitute the padding from original image\\n        img_new[:zoom_shift,:] = hor_top\\n        img_new[-zoom_shift:,:] = hor_bottom\\n        img_new[:,:zoom_shift] = ver_left\\n        img_new[:,-zoom_shift:] = ver_right     \\n        \\n    return img_new.reshape(75,75).astype(np.float32)\"}]], \"revisionId\": [[null]], \"properties\": [\"np\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091953\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091953\"}}, \"47\": {\"id\": 47, \"state\": [4], \"command\": [{\"id\": [47], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"matplotlib.rcParams['figure.figsize'] = (20.0, 14.0)\\nimage = band_1_test[3].copy()\\nplt.subplot(3, 5, 1)\\nplt.title(\\\"Original Image\\\")\\nplt.imshow(image)\\nplt.subplot(3, 5, 2)\\ngenerated_image = rotate_image(image,40)\\nplt.title(\\\"Rotation by +ve degree\\\")\\nplt.imshow(generated_image)\\nplt.subplot(3, 5, 3)\\ngenerated_image = rotate_image(image,-40)\\nplt.title(\\\"Rotation by -ve degree\\\")\\nplt.imshow(generated_image)\\nplt.subplot(3, 5, 4)\\ngenerated_image = translate_horizontal(image,10)\\nplt.title(\\\"Horizonation translation to right\\\")\\nplt.imshow(generated_image)\\nplt.subplot(3, 5, 5)\\ngenerated_image = translate_horizontal(image,-10)\\nplt.title(\\\"Horizonation translation to left\\\")\\nplt.imshow(generated_image)\\nplt.subplot(3, 5, 6)\\ngenerated_image = translate_vertical(image,10)\\nplt.title(\\\"Vertical translation downward\\\")\\nplt.imshow(generated_image)\\nplt.subplot(3, 5, 7)\\ngenerated_image = translate_vertical(image,-10)\\nplt.title(\\\"Vertical translation upward\\\")\\nplt.imshow(generated_image)\\nplt.subplot(3, 5, 8)\\ngenerated_image = translate_positive_diagonal(image,10)\\nplt.title(\\\"SE translation\\\")\\nplt.imshow(generated_image)\\nplt.subplot(3, 5, 9)\\ngenerated_image = translate_positive_diagonal(image,-10)\\nplt.title(\\\"NW translation\\\")\\nplt.imshow(generated_image)\\nplt.subplot(3, 5, 10)\\ngenerated_image = translate_negative_diagonal(image,10)\\nplt.title(\\\"NE translation\\\")\\nplt.imshow(generated_image)\\nplt.subplot(3, 5, 11)\\ngenerated_image = translate_negative_diagonal(image,-10)\\nplt.title(\\\"SW translation\\\")\\nplt.imshow(generated_image)\\nplt.subplot(3, 5, 12)\\ngenerated_image = flip(image,0)\\nplt.title(\\\"Vertical flip\\\")\\nplt.imshow(generated_image)\\nplt.subplot(3, 5, 13)\\ngenerated_image = flip(image,1)\\nplt.title(\\\"Horizontal flip\\\")\\nplt.imshow(generated_image)\\nplt.subplot(3, 5, 14)\\ngenerated_image = zoom(image,10)\\nplt.title(\\\"Zoom in\\\")\\nplt.imshow(generated_image)\\nplt.subplot(3, 5, 15)\\ngenerated_image = zoom(image,-10)\\nplt.title(\\\"Zoom out\\\")\\nplt.imshow(generated_image)\\nplt.show()\"}]], \"revisionId\": [[null]], \"properties\": [\"matplotlib\", \"band_1_test\", \"plt\", \"rotate_image\", \"translate_horizontal\", \"translate_vertical\", \"translate_positive_diagonal\", \"translate_negative_diagonal\", \"flip\", \"zoom\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091972\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091972\"}}, \"48\": {\"id\": 48, \"state\": [4], \"command\": [{\"id\": [48], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def augment_data(band1, band2, angles, labels):\\n    \\n    '''a function to augment band1 and band2 image'''\\n    \\n    # list to store the generated data\\n    band1_generated = []\\n    band2_generated = []\\n    angles_generated = []\\n    labels_generated = []\\n    \\n    # iterate through each point in train set\\n    for i in range(labels.shape[0]):\\n        \\n        # rotate by positive degree\\n        angle = np.random.randint(5,20)\\n        band1_generated.append(rotate_image(band1[i],angle)) \\n        band2_generated.append(rotate_image(band2[i],angle))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])\\n        \\n        # rotate by negative degree\\n        angle = np.random.randint(5,20)\\n        band1_generated.append(rotate_image(band1[i],-angle)) \\n        band2_generated.append(rotate_image(band2[i],-angle))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])\\n        \\n        # positive horizontal shift\\n        shift = np.random.randint(3,7)\\n        band1_generated.append(translate_horizontal(band1[i],+shift)) \\n        band2_generated.append(translate_horizontal(band2[i],+shift))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])\\n        \\n        # negative horizontal shift\\n        shift = np.random.randint(3,7) \\n        band1_generated.append(translate_horizontal(band1[i],-shift)) \\n        band2_generated.append(translate_horizontal(band2[i],-shift))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])\\n        \\n        # positive vertical shift\\n        shift = np.random.randint(0,7)  \\n        band1_generated.append(translate_vertical(band1[i],+shift)) \\n        band2_generated.append(translate_vertical(band2[i],+shift))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])\\n        \\n        # negative vertical shift\\n        shift = np.random.randint(3,7) \\n        band1_generated.append(translate_vertical(band1[i],-shift)) \\n        band2_generated.append(translate_vertical(band2[i],-shift))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])\\n        \\n        # translate along positive diagonal in positive direction\\n        shift = np.random.randint(3,7)  \\n        band1_generated.append(translate_positive_diagonal(band1[i],+shift)) \\n        band2_generated.append(translate_positive_diagonal(band2[i],+shift))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])\\n        \\n        # translate along positive diagonal in negative direction\\n        shift = np.random.randint(3,7)  \\n        band1_generated.append(translate_positive_diagonal(band1[i],-shift)) \\n        band2_generated.append(translate_positive_diagonal(band2[i],-shift))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])\\n        \\n        # translate along negative diagonal in positive direction\\n        shift = np.random.randint(3,7)   \\n        band1_generated.append(translate_negative_diagonal(band1[i],+shift)) \\n        band2_generated.append(translate_negative_diagonal(band2[i],+shift))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])\\n        \\n        # translate along negative diagonal in negative direction\\n        shift = np.random.randint(3,7)   \\n        band1_generated.append(translate_negative_diagonal(band1[i],-shift)) \\n        band2_generated.append(translate_negative_diagonal(band2[i],-shift))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])\\n        \\n        # vertical flip\\n        band1_generated.append(flip(band1[i],0)) \\n        band2_generated.append(flip(band2[i],0))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])\\n        \\n        # horizontal flip\\n        band1_generated.append(flip(band1[i],1)) \\n        band2_generated.append(flip(band2[i],1))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])\\n        \\n        # zoom in image\\n        zoom_shift = np.random.randint(2,5)\\n        band1_generated.append(zoom(band1[i],zoom_shift)) \\n        band2_generated.append(zoom(band2[i],zoom_shift))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])\\n        \\n        # zoom out image\\n        zoom_shift = np.random.randint(2,5) \\n        band1_generated.append(zoom(band1[i],-zoom_shift)) \\n        band2_generated.append(zoom(band2[i],-zoom_shift))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])        \\n        \\n    # convert the generated data into numpy array\\n    band1_generated = np.array(band1_generated)\\n    band2_generated = np.array(band2_generated)\\n    angles_generated = np.array(angles_generated)\\n    labels_generated = np.array(labels_generated)\\n    \\n    # concatenate the generated data to original train set\\n    band1_augmented = np.concatenate((band1, band1_generated),axis=0)\\n    band2_augmented = np.concatenate((band2, band2_generated),axis=0)\\n    angles_augmented = np.concatenate((angles, angles_generated),axis=0)\\n    labels_augmented = np.concatenate((labels, labels_generated),axis=0)\\n    \\n    return band1_augmented, band2_augmented, angles_augmented, labels_augmented\"}]], \"revisionId\": [[null]], \"properties\": [\"np\", \"labels\", \"rotate_image\", \"angles\", \"translate_horizontal\", \"translate_vertical\", \"translate_positive_diagonal\", \"translate_negative_diagonal\", \"flip\", \"zoom\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091990\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091990\"}}, \"49\": {\"id\": 49, \"state\": [4], \"command\": [{\"id\": [49], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# augment train set\\nband_1_train, band_2_train, angles_train, labels_train = \\\\\\n    augment_data(band_1_train, band_2_train, angles_train, labels_train)\"}]], \"revisionId\": [[null]], \"properties\": [\"augment_data\", \"band_1_train\", \"band_2_train\", \"angles_train\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092051\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092051\"}}, \"50\": {\"id\": 50, \"state\": [4], \"command\": [{\"id\": [50], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"print(\\\"Shape of band_1_train:\\\",band_1_train.shape)\\nprint(\\\"Shape of band_2_train:\\\",band_2_train.shape)\\nprint(\\\"Shape of angles_train:\\\",angles_train.shape)\\nprint(\\\"Shape of labels_train:\\\",labels_train.shape)\"}]], \"revisionId\": [[null]], \"properties\": [\"band_1_train\", \"band_2_train\", \"angles_train\", \"labels_train\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092070\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092070\"}}, \"51\": {\"id\": 51, \"state\": [4], \"command\": [{\"id\": [51], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"image_train = np.concatenate([band_1_train[:, :, :, np.newaxis],\\n                             band_2_train[:, :, :, np.newaxis],\\n                             ((band_1_train+band_2_train)/2)[:, :, :, np.newaxis]],\\n                             axis=-1)\"}]], \"revisionId\": [[null]], \"properties\": [\"np\", \"band_1_train\", \"band_2_train\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092089\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092089\"}}, \"52\": {\"id\": 52, \"state\": [4], \"command\": [{\"id\": [52], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"image_validation = np.concatenate([band_1_validation[:, :, :, np.newaxis],\\n                             band_2_validation[:, :, :, np.newaxis],\\n                             ((band_1_validation+band_2_validation)/2)[:, :, :, np.newaxis]],\\n                             axis=-1)\"}]], \"revisionId\": [[null]], \"properties\": [\"np\", \"band_1_validation\", \"band_2_validation\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092106\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092106\"}}, \"53\": {\"id\": 53, \"state\": [4], \"command\": [{\"id\": [53], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"image_test = np.concatenate([band_1_test[:, :, :, np.newaxis],\\n                             band_2_test[:, :, :, np.newaxis],\\n                             ((band_1_test+band_2_test)/2)[:, :, :, np.newaxis]],\\n                             axis=-1)\"}]], \"revisionId\": [[null]], \"properties\": [\"np\", \"band_1_test\", \"band_2_test\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092123\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092123\"}}, \"54\": {\"id\": 54, \"state\": [4], \"command\": [{\"id\": [54], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# delete the unnecessary variables out of memory\\ndel(band_1_train, band_1_validation, band_1_test, band_2_train, band_2_validation, band_2_test)\"}]], \"revisionId\": [[null]], \"properties\": []}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092140\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092140\"}}, \"55\": {\"id\": 55, \"state\": [4], \"command\": [{\"id\": [55], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"print(\\\"Shape of image_train:\\\",image_train.shape)\\nprint(\\\"Shape of image_validation:\\\",image_validation.shape)\\nprint(\\\"Shape of image_test:\\\",image_test.shape)\"}]], \"revisionId\": [[null]], \"properties\": [\"image_train\", \"image_validation\", \"image_test\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092158\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092158\"}}, \"56\": {\"id\": 56, \"state\": [4], \"command\": [{\"id\": [56], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"import tensorflow as tf\\nfrom tensorflow.python.framework import ops\\nops.reset_default_graph()\\ntf.set_random_seed(tf_rand_seed)\\n# sess = tf.InteractiveSession()\"}]], \"revisionId\": [[null]], \"properties\": [\"tf_rand_seed\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092176\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092176\"}}, \"57\": {\"id\": 57, \"state\": [4], \"command\": [{\"id\": [57], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"labels_train = pd.get_dummies(labels_train).as_matrix()\\nlabels_validation = pd.get_dummies(labels_validation).as_matrix()\"}]], \"revisionId\": [[null]], \"properties\": [\"pd\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092194\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092194\"}}, \"58\": {\"id\": 58, \"state\": [4], \"command\": [{\"id\": [58], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"print(\\\"Shape of labels_train:\\\", labels_train.shape)\\nprint(\\\"Shape of labels_validation:\\\", labels_validation.shape)\"}]], \"revisionId\": [[null]], \"properties\": [\"labels_train\", \"labels_validation\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092211\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092211\"}}, \"59\": {\"id\": 59, \"state\": [4], \"command\": [{\"id\": [59], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# image dimensions\\nwidth = 75\\nheight = 75\\nnum_channels = 3\\nflat = width * height\\nnum_classes = 2\"}]], \"revisionId\": [[null]], \"properties\": []}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092229\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092229\"}}, \"60\": {\"id\": 60, \"state\": [4], \"command\": [{\"id\": [60], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"image = tf.placeholder(tf.float32, shape=[None, height, width, num_channels])\\n# angle = tf.placeholder(tf.float32, shape= [None, 1])\\ny_true = tf.placeholder(tf.int32, shape=[None, num_classes])\\nkeep_prob = tf.placeholder(tf.float32)\"}]], \"revisionId\": [[null]], \"properties\": [\"tf\", \"height\", \"width\", \"num_channels\", \"num_classes\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092247\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092247\"}}, \"61\": {\"id\": 61, \"state\": [4], \"command\": [{\"id\": [61], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def create_weights(shape):\\n    '''a function to create weight tensor'''\\n    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\\n \\ndef create_biases(size):\\n    '''a function to create bias tensor'''\\n    return tf.Variable(tf.constant(0.05, shape=[size]))\"}]], \"revisionId\": [[null]], \"properties\": [\"tf\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092265\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092265\"}}, \"62\": {\"id\": 62, \"state\": [4], \"command\": [{\"id\": [62], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def create_convolutional_layer(input,\\n                               num_input_channels,\\n                               conv_filter_size,\\n                               max_pool_filter_size,\\n                               num_filters):  \\n    \\n    '''a function to create convoutional layer'''\\n    \\n    # create filter for the convolutional layer\\n    weights = create_weights(shape=[conv_filter_size, conv_filter_size, num_input_channels, num_filters])\\n    \\n    # create biases\\n    biases = create_biases(num_filters)\\n    \\n    # create covolutional layer\\n    layer = tf.nn.conv2d(input=input,\\n                     filter=weights,\\n                     strides=[1, 1, 1, 1],\\n                     padding='SAME')\\n    \\n    # add the bias to the convolutional layer\\n    layer += biases\\n    \\n    # relu activation layer fed into layer\\n    layer = tf.nn.relu(layer)\\n    \\n    # max pooling to half the size of the image\\n    layer = tf.nn.max_pool(value=layer,\\n                            ksize=[1, max_pool_filter_size, max_pool_filter_size, 1],\\n                            strides=[1, 2, 2, 1],\\n                            padding='SAME')\\n        \\n    # return the output layer of the convolution\\n    return layer\"}]], \"revisionId\": [[null]], \"properties\": [\"create_weights\", \"create_biases\", \"tf\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092281\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092281\"}}, \"63\": {\"id\": 63, \"state\": [4], \"command\": [{\"id\": [63], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def create_flatten_layer(layer):\\n    \\n    '''a function for creating flattened layer from convolutional output'''\\n    \\n    # extract the shape of the layer\\n    layer_shape = layer.get_shape()\\n    # calculate the number features of the flattened layer\\n    num_features = layer_shape[1:4].num_elements()\\n    # create the flattened layer\\n    layer = tf.reshape(layer, [-1, num_features])\\n    # return the layer\\n    return layer\"}]], \"revisionId\": [[null]], \"properties\": [\"tf\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092298\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092298\"}}, \"64\": {\"id\": 64, \"state\": [4], \"command\": [{\"id\": [64], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def create_fc_layer(input,          \\n                    num_inputs,    \\n                    num_outputs,\\n                    use_relu=True,\\n                    dropout = False, \\n                    keep_prob = 0.2):\\n    \\n    '''a function for creating fully connected layer'''\\n    \\n    #Let's define trainable weights and biases.\\n    weights = create_weights(shape=[num_inputs, num_outputs])\\n    biases = create_biases(num_outputs)\\n    \\n    # matrix multiplication between input and weight matrix\\n    layer = tf.matmul(input, weights) + biases\\n    \\n    # add relu activation if wanted\\n    if use_relu:\\n        layer = tf.nn.relu(layer)\\n        \\n    # if dropout is wanted add dropout\\n    if dropout:        \\n        layer = tf.nn.dropout(layer, keep_prob)\\n    \\n    # return layer\\n    return layer\"}]], \"revisionId\": [[null]], \"properties\": [\"create_weights\", \"create_biases\", \"tf\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092314\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092314\"}}, \"65\": {\"id\": 65, \"state\": [4], \"command\": [{\"id\": [65], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# paramters for 1st convolutional layer\\nconv1_features = 64\\nconv1_filter_size = 3\\nmax_pool_size1 = 2\\n\\n# paramters for 2nd convolutional layer\\nconv2_features = 128\\nconv2_filter_size = 3\\nmax_pool_size2 = 2\\n\\n# paramters for 3rd convolutional layer\\nconv3_features = 128\\nconv3_filter_size = 3\\nmax_pool_size3 = 2\\n\\n# paramters for 4th convolutional layer\\nconv4_features = 64\\nconv4_filter_size = 3\\nmax_pool_size4 = 2\\n\\n# number of featuers of 1st fully connected layer\\nfc_layer_size1 = 512\\n\\n# number of featuers of 2nd fully connected layer\\nfc_layer_size2 = 256\"}]], \"revisionId\": [[null]], \"properties\": []}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092332\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092332\"}}, \"66\": {\"id\": 66, \"state\": [4], \"command\": [{\"id\": [66], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"layer_conv1 = create_convolutional_layer(input=image,\\n                                         num_input_channels= num_channels,\\n                                         conv_filter_size = conv1_filter_size,\\n                                         max_pool_filter_size = max_pool_size1,\\n                                         num_filters = conv1_features)\\nlayer_conv1\"}]], \"revisionId\": [[null]], \"properties\": [\"create_convolutional_layer\", \"image\", \"num_channels\", \"conv1_filter_size\", \"max_pool_size1\", \"conv1_features\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092350\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092350\"}}, \"67\": {\"id\": 67, \"state\": [4], \"command\": [{\"id\": [67], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"layer_conv2 = create_convolutional_layer(input=layer_conv1,\\n                                         num_input_channels= conv1_features,\\n                                         conv_filter_size = conv2_filter_size,\\n                                         max_pool_filter_size = max_pool_size2,\\n                                         num_filters = conv2_features)\\nlayer_conv2\"}]], \"revisionId\": [[null]], \"properties\": [\"create_convolutional_layer\", \"layer_conv1\", \"conv1_features\", \"conv2_filter_size\", \"max_pool_size2\", \"conv2_features\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092368\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092368\"}}, \"68\": {\"id\": 68, \"state\": [4], \"command\": [{\"id\": [68], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"layer_conv3 = create_convolutional_layer(input=layer_conv2,\\n                                         num_input_channels= conv2_features,\\n                                         conv_filter_size = conv3_filter_size,\\n                                         max_pool_filter_size = max_pool_size3,\\n                                         num_filters = conv3_features)\\nlayer_conv3\"}]], \"revisionId\": [[null]], \"properties\": [\"create_convolutional_layer\", \"layer_conv2\", \"conv2_features\", \"conv3_filter_size\", \"max_pool_size3\", \"conv3_features\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092386\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092386\"}}, \"69\": {\"id\": 69, \"state\": [4], \"command\": [{\"id\": [69], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"layer_conv4 = create_convolutional_layer(input=layer_conv3,\\n                                         num_input_channels= conv3_features,\\n                                         conv_filter_size = conv4_filter_size,\\n                                         max_pool_filter_size = max_pool_size4,\\n                                         num_filters = conv4_features)\\nlayer_conv4\"}]], \"revisionId\": [[null]], \"properties\": [\"create_convolutional_layer\", \"layer_conv3\", \"conv3_features\", \"conv4_filter_size\", \"max_pool_size4\", \"conv4_features\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092403\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092403\"}}, \"70\": {\"id\": 70, \"state\": [4], \"command\": [{\"id\": [70], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"layer_flat = create_flatten_layer(layer_conv4)\\nlayer_flat\"}]], \"revisionId\": [[null]], \"properties\": [\"create_flatten_layer\", \"layer_conv4\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092421\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092421\"}}, \"71\": {\"id\": 71, \"state\": [4], \"command\": [{\"id\": [71], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# layer_angle = create_fc_layer(input = angle,\\n#                               num_inputs=1,\\n#                               num_outputs=1,\\n#                               use_relu= True)\"}]], \"revisionId\": [[null]], \"properties\": []}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092439\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092439\"}}, \"72\": {\"id\": 72, \"state\": [4], \"command\": [{\"id\": [72], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# combined_layer = tf.concat((layer_flat, layer_angle), axis=1)\"}]], \"revisionId\": [[null]], \"properties\": []}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092455\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092455\"}}, \"73\": {\"id\": 73, \"state\": [4], \"command\": [{\"id\": [73], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# layer_fc1 = create_fc_layer(input=combined_layer,\\n#                             num_inputs=combined_layer.get_shape()[1:4].num_elements(),\\n#                             num_outputs=fc_layer_size1,\\n#                             use_relu=True,\\n#                             dropout =True,\\n#                             keep_prob = keep_prob)\"}]], \"revisionId\": [[null]], \"properties\": []}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092472\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092472\"}}, \"74\": {\"id\": 74, \"state\": [4], \"command\": [{\"id\": [74], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"layer_fc1 = create_fc_layer(input=layer_flat,\\n                            num_inputs=layer_flat.get_shape()[1:4].num_elements(),\\n                            num_outputs=fc_layer_size1,\\n                            use_relu=True,\\n                            dropout =True,\\n                            keep_prob = keep_prob)\\nlayer_fc1\"}]], \"revisionId\": [[null]], \"properties\": [\"create_fc_layer\", \"layer_flat\", \"fc_layer_size1\", \"keep_prob\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092511\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092511\"}}, \"75\": {\"id\": 75, \"state\": [4], \"command\": [{\"id\": [75], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"layer_fc2 = create_fc_layer(input=layer_fc1,\\n                            num_inputs=fc_layer_size1,\\n                            num_outputs=fc_layer_size2,\\n                            use_relu=True,\\n                            dropout =True,\\n                            keep_prob = keep_prob)\\nlayer_fc2\"}]], \"revisionId\": [[null]], \"properties\": [\"create_fc_layer\", \"layer_fc1\", \"fc_layer_size1\", \"fc_layer_size2\", \"keep_prob\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092529\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092529\"}}, \"76\": {\"id\": 76, \"state\": [4], \"command\": [{\"id\": [76], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"output_layer = create_fc_layer(input=layer_fc2,\\n                     num_inputs = fc_layer_size2,\\n                     num_outputs = num_classes,\\n                     use_relu=False)\\noutput_layer\"}]], \"revisionId\": [[null]], \"properties\": [\"create_fc_layer\", \"layer_fc2\", \"fc_layer_size2\", \"num_classes\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092547\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092547\"}}, \"77\": {\"id\": 77, \"state\": [4], \"command\": [{\"id\": [77], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# softmax operation on the output layer\\ny_pred = tf.nn.softmax(output_layer)\\n# extract the vector of predicted class\\ny_pred_cls = tf.argmax(y_pred, axis=1, output_type=tf.int32)\\n# extract the vector of labels\\ny_true_cls = tf.argmax(y_true, axis=1, output_type=tf.int32)\"}]], \"revisionId\": [[null]], \"properties\": [\"tf\", \"output_layer\", \"y_true\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092565\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092565\"}}, \"78\": {\"id\": 78, \"state\": [4], \"command\": [{\"id\": [78], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# extract the vector of correct prediction\\ncorrect_prediction = tf.equal(y_pred_cls, y_true_cls)\\n# operation to calculate accuracy\\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\"}]], \"revisionId\": [[null]], \"properties\": [\"tf\", \"y_pred_cls\", \"y_true_cls\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092581\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092581\"}}, \"79\": {\"id\": 79, \"state\": [4], \"command\": [{\"id\": [79], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# operation to calculate cross entropy\\ncross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=output_layer,\\n                                                    labels=y_true)\\n# mean of cross entropy to act as the loss\\nloss = tf.reduce_mean(cross_entropy)\"}]], \"revisionId\": [[null]], \"properties\": [\"tf\", \"output_layer\", \"y_true\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092599\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092599\"}}, \"80\": {\"id\": 80, \"state\": [4], \"command\": [{\"id\": [80], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# sess.run(tf.global_variables_initializer())\\n# loss.eval(feed_dict={image: image_validation,\\n#                          angle: np.transpose([angles_validation]),\\n#                          y_true: labels_validation, keep_prob: 1.0})\"}]], \"revisionId\": [[null]], \"properties\": []}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092616\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092616\"}}, \"81\": {\"id\": 81, \"state\": [4], \"command\": [{\"id\": [81], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# learning rate of optimizer\\nlearning_rate = (1e-3)*0.30\\n# train step\\ntrain_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\"}]], \"revisionId\": [[null]], \"properties\": [\"tf\", \"loss\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092633\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092633\"}}, \"82\": {\"id\": 82, \"state\": [4], \"command\": [{\"id\": [82], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# lists to store the train loss, validation loss, validation accuracy at each iteration\\ntrain_loss = []\\nvalid_loss = []\\nvalid_acc = []\\n\\n# batch size\\nbatch_size = 255\\n# max iteration\\nmax_iter = 700\"}]], \"revisionId\": [[null]], \"properties\": []}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092650\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092650\"}}, \"83\": {\"id\": 83, \"state\": [4], \"command\": [{\"id\": [83], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# create a saver object\\nsaver = tf.train.Saver(max_to_keep=1)\\n\\n# variables to store the accuracy, loss, iteration of our best model\\nbest_accuracy = 0\\nbest_loss = 1000000\\nbest_iteration = None\\n\\niteration = 0\\n\\n# create a graph session and optimize under it\\nwith tf.Session() as sess:\\n    \\n    # initialize variables\\n    sess.run(tf.global_variables_initializer())\\n\\n    # while 57 minutes have not elapsed (to finish before the kernel is killed)\\n    while (time.time()-t1) < 3420:\\n        \\n        # break if max iteration is reached\\n        if iteration >= max_iter:\\n            break\\n\\n        # randomly choosing the indices of the batch \\n        rand_index = np.random.choice(labels_train.shape[0], size=batch_size)\\n\\n        # extract the batch image and labels\\n        image_rand = image_train[rand_index]\\n#         angles_rand = angles_train[rand_index]\\n        labels_rand = labels_train[rand_index]\\n\\n        # feed dictionary for batch\\n        feed_dict_batch =  {image: image_rand,\\n#                             angle: np.transpose([angles_rand]),\\n                            y_true: labels_rand,\\n                            keep_prob: 0.7}\\n        # feed dictionary for train\\n        feed_dict_train =  {image: image_rand,\\n#                             angle: np.transpose([angles_rand]),\\n                            y_true: labels_rand,\\n                            keep_prob: 1.0}\\n        # feed dictionary for validation\\n        feed_dict_validation =  {image: image_validation,\\n#                                  angle: np.transpose([angles_validation]),\\n                                 y_true: labels_validation,\\n                                 keep_prob: 1.0}\\n        \\n        # execute optimization step\\n        sess.run(train_step, feed_dict=feed_dict_batch)\\n\\n        # calculate temporary train loss and append it to the designated list\\n        temp_train_loss = loss.eval(session=sess, feed_dict=feed_dict_train)\\n        train_loss.append(temp_train_loss)\\n        # calculate temporary validation loss and append it to the designated list\\n        temp_validation_loss = loss.eval(session=sess, feed_dict=feed_dict_validation)\\n        valid_loss.append(temp_validation_loss)\\n        # calculate temporary validation accuracy and append it to the designated list\\n        temp_validation_accuracy = accuracy.eval(session=sess, feed_dict=feed_dict_validation)\\n        valid_acc.append(temp_validation_accuracy)\\n\\n        # if the valid loss is tied with best recorded so far but valid acc is better then\\n        # update the parameters of the best model and save the model\\n        if (temp_validation_loss == best_loss) and (temp_validation_accuracy > best_accuracy):\\n            best_accuracy = temp_validation_accuracy\\n            best_loss = temp_validation_loss\\n            best_iteration = iteration           \\n            saver.save(sess, './my-model', global_step = best_iteration)\\n        \\n        # if valid accuracy is better than best recorded so far then update the best valid accuracy\\n        if temp_validation_accuracy > best_accuracy:\\n            best_accuracy = temp_validation_accuracy\\n        \\n        # if valid loss is better than best recorded so far then\\n        # update the parameters of the best model and save the model\\n        if temp_validation_loss < best_loss:\\n            best_loss = temp_validation_loss\\n            best_iteration = iteration          \\n            saver.save(sess, './my-model', global_step = best_iteration)\\n\\n        # print metric info\\n        print(\\\"iterations:\\\",iteration,\\n              \\\"| train_loss:\\\", temp_train_loss,\\n              \\\"| validation_loss:\\\", temp_validation_loss,\\n              \\\"| valid_accuracy:\\\", temp_validation_accuracy)\\n        \\n        # increment iteration\\n        iteration = iteration+1\"}]], \"revisionId\": [[null]], \"properties\": [\"tf\", \"time\", \"t1\", \"max_iter\", \"np\", \"labels_train\", \"batch_size\", \"image_train\", \"image\", \"y_true\", \"keep_prob\", \"image_validation\", \"labels_validation\", \"train_step\", \"loss\", \"train_loss\", \"valid_loss\", \"accuracy\", \"valid_acc\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092668\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092668\"}}, \"84\": {\"id\": 84, \"state\": [4], \"command\": [{\"id\": [84], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# delete unnecessary variables out of memory\\ndel(image_train, image_validation, angles_train, angles_validation, labels_train, labels_validation)\"}]], \"revisionId\": [[null]], \"properties\": []}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092685\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092685\"}}, \"85\": {\"id\": 85, \"state\": [4], \"command\": [{\"id\": [85], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# t5 = time.time()\\n\\nwith tf.Session() as sess:    \\n    \\n    # restore the best model\\n    model_path = \\\"./\\\"+\\\"my-model-\\\"+str(best_iteration)\\n    saver.restore(sess, model_path)\\n    \\n    # break the test set into k folds other wise kernel will be out of memory\\n    n = len(iD)\\n    k = 12\\n    step = n//k\\n    \\n    # array to store the prediction\\n    preds = np.array([])\\n\\n    # iterate through each fold\\n    for i in range(k):\\n\\n        # start and end indices of the fold\\n        start = (step*i)\\n        end = (step*(i+1)) \\n    \\n        # feed dictionary for the fold\\n        feed_dict_test =  {image: image_test[start:end],\\n#                            angle: np.transpose([angles_test[start:end]]),\\n                           keep_prob: 1.0}\\n\\n        # evaluate predictions of the fold\\n        fold_preds = y_pred.eval(session=sess, feed_dict = feed_dict_test)[:,1]\\n        # append the predictions of the fold to the designated array\\n        preds = np.append(preds, fold_preds)\\n    \\n    # save the submission csv file\\n    submission_path = \\\"./submission.csv\\\"\\n    submission = pd.DataFrame({\\\"id\\\": iD, \\\"is_iceberg\\\": preds})\\n    submission.to_csv(submission_path, header = True, index=False)\\n    \\n    # save the csv file containing performance metrics of the best model \\n    results = pd.DataFrame([int(best_iteration),train_loss[best_iteration],\\n                            valid_loss[best_iteration], valid_acc[best_iteration]],\\n                           index=[\\\"iteration\\\", \\\"train loss\\\", \\\"valid loss\\\", \\\"accuracy\\\"],\\n                           columns = [\\\"results\\\"])    \\n    results_path = \\\"./results.csv\\\"    \\n    results.to_csv(results_path, header = True, index=True)\\n    \\n# t6 = time.time()\\n# print(\\\"time take for prediction: \\\", t6-t5)\"}]], \"revisionId\": [[null]], \"properties\": [\"tf\", \"best_iteration\", \"saver\", \"iD\", \"np\", \"pd\", \"train_loss\", \"valid_loss\", \"valid_acc\", \"image\", \"image_test\", \"keep_prob\", \"y_pred\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092703\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092703\"}}, \"86\": {\"id\": 86, \"state\": [4], \"command\": [{\"id\": [86], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"plt.figure(figsize=(16, 8), dpi= 80, facecolor='w', edgecolor='k')\\niterations = list(range(1,iteration+1))\\nplt.plot(iterations, train_loss, label = \\\"train loss\\\")\\nplt.plot(iterations, valid_loss, label = \\\"valid loss\\\")\\nplt.title(\\\"Loss\\\")\\nplt.xlabel(\\\"iter\\\")\\nplt.ylabel(\\\"loss\\\")\\nplt.legend()\\nplt.grid()\\nplt.show()\"}]], \"revisionId\": [[null]], \"properties\": [\"plt\", \"iteration\", \"train_loss\", \"valid_loss\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092722\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092722\"}}, \"87\": {\"id\": 87, \"state\": [4], \"command\": [{\"id\": [87], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"plt.figure(figsize=(16, 8), dpi= 80, facecolor='w', edgecolor='k')\\nplt.plot(iterations, valid_acc, label = \\\"train loss\\\")\\nplt.title(\\\"Accuracy\\\")\\nplt.xlabel(\\\"iter\\\")\\nplt.ylabel(\\\"accuracy\\\")\\nplt.grid()\\nplt.show()\"}]], \"revisionId\": [[null]], \"properties\": [\"plt\", \"iterations\", \"valid_acc\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092741\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092741\"}}}], \"branches\": [{\"Id\": {\"Id\": [[1]], \"createdAt\": [[\"2021-09-17 19:30:36.092761\"]], \"lastModifiedAt\": [[\"2021-09-17 19:30:36.092764\"]], \"sourceBranch\": [[null]], \"sourceWorkflow\": [[null]], \"isDefault\": [[true]], \"properties\": [[null]], \"workflows\": {\"1\": {\"id\": [[1]], \"createdAt\": [[\"2021-09-17 19:30:36.092751\"]], \"action\": [[\"create\"]], \"packageId\": [[null]], \"commandId\": [[null]], \"actionModule\": [[null]], \"modules\": {\"1\": {\"id\": 1, \"state\": [4], \"command\": [{\"id\": [1], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# import time\\nimport time\\nt1 = time.time()\"}]], \"revisionId\": [[null]], \"properties\": []}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091117\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091117\"}}, \"2\": {\"id\": 2, \"state\": [4], \"command\": [{\"id\": [2], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"import math\\nimport random\\nimport pandas as pd\\nimport numpy as np\\nimport cv2\\nfrom sklearn.preprocessing import MinMaxScaler\\nimport matplotlib\\nfrom matplotlib import pyplot as plt\\n \"}]], \"revisionId\": [[null]], \"properties\": []}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091152\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091152\"}}, \"3\": {\"id\": 3, \"state\": [4], \"command\": [{\"id\": [3], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# np_rand_seed = random.randint(0,100)\\n# tf_rand_seed = random.randint(0,100)\\nnp_rand_seed = 97\\ntf_rand_seed = 82\\nnp.random.seed(np_rand_seed)\"}]], \"revisionId\": [[null]], \"properties\": [\"np\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091173\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091173\"}}, \"4\": {\"id\": 4, \"state\": [4], \"command\": [{\"id\": [4], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"data = pd.read_json('../input/train.json')\\ntest_data = pd.read_json('../input/test.json')\"}]], \"revisionId\": [[null]], \"properties\": [\"pd\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091192\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091192\"}}, \"5\": {\"id\": 5, \"state\": [4], \"command\": [{\"id\": [5], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"data.head(5)\"}]], \"revisionId\": [[null]], \"properties\": [\"data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091209\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091209\"}}, \"6\": {\"id\": 6, \"state\": [4], \"command\": [{\"id\": [6], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"test_data.head(5)\"}]], \"revisionId\": [[null]], \"properties\": [\"test_data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091227\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091227\"}}, \"7\": {\"id\": 7, \"state\": [4], \"command\": [{\"id\": [7], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"print(\\\"Shape of train set:\\\", data.shape)\\nprint(\\\"Shape of test set:\\\", test_data.shape)\"}]], \"revisionId\": [[null]], \"properties\": [\"data\", \"test_data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091245\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091245\"}}, \"8\": {\"id\": 8, \"state\": [4], \"command\": [{\"id\": [8], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"print(\\\"Shape of band 1:\\\",  np.shape(data.band_1.iloc[0]))\\nprint(\\\"Shape of band 2:\\\",  np.shape(data.band_2.iloc[0]))\"}]], \"revisionId\": [[null]], \"properties\": [\"np\", \"data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091262\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091262\"}}, \"9\": {\"id\": 9, \"state\": [4], \"command\": [{\"id\": [9], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"print(\\\"Type of band 1:\\\",  type(data.band_1.iloc[0]))\\nprint(\\\"Type of band 2:\\\",  type(data.band_2.iloc[0]))\"}]], \"revisionId\": [[null]], \"properties\": [\"data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091279\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091279\"}}, \"10\": {\"id\": 10, \"state\": [4], \"command\": [{\"id\": [10], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"data[data['inc_angle']=='na'] = data[data['inc_angle']!='na']['inc_angle'].mean()\"}]], \"revisionId\": [[null]], \"properties\": [\"data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091300\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091300\"}}, \"11\": {\"id\": 11, \"state\": [4], \"command\": [{\"id\": [11], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"data['inc_angle'] = data['inc_angle'].apply(lambda x: math.radians(x))\"}]], \"revisionId\": [[null]], \"properties\": [\"data\", \"math\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091318\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091318\"}}, \"12\": {\"id\": 12, \"state\": [4], \"command\": [{\"id\": [12], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"data.inc_angle.head()\"}]], \"revisionId\": [[null]], \"properties\": [\"data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091336\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091336\"}}, \"13\": {\"id\": 13, \"state\": [4], \"command\": [{\"id\": [13], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def find_missing_data(series, shape):\\n    \\n    '''function which return the count and the index of mismatched data'''    \\n    count = 0\\n    missing_list = []\\n    for i,x in enumerate(series):   \\n        if np.shape(series.iloc[i]) != shape:\\n            missing_list.append(i)\\n            count += 1\\n            \\n    return missing_list, count\"}]], \"revisionId\": [[null]], \"properties\": [\"np\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091356\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091356\"}}, \"14\": {\"id\": 14, \"state\": [4], \"command\": [{\"id\": [14], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"missing_list1, count1 = find_missing_data(data.band_1, (5625,))\\nprint(\\\"count: \\\", count1)\\nprint(\\\"missing data: \\\", missing_list1)\"}]], \"revisionId\": [[null]], \"properties\": [\"find_missing_data\", \"data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091374\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091374\"}}, \"15\": {\"id\": 15, \"state\": [4], \"command\": [{\"id\": [15], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"missing_list2, count2 = find_missing_data(data.band_2, (5625,))\\nprint(\\\"count: \\\", count1)\\nprint(\\\"missing data: \\\", missing_list2)\"}]], \"revisionId\": [[null]], \"properties\": [\"find_missing_data\", \"data\", \"count1\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091392\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091392\"}}, \"16\": {\"id\": 16, \"state\": [4], \"command\": [{\"id\": [16], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"missing_list1 == missing_list2\"}]], \"revisionId\": [[null]], \"properties\": [\"missing_list1\", \"missing_list2\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091411\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091411\"}}, \"17\": {\"id\": 17, \"state\": [4], \"command\": [{\"id\": [17], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def drop_data(df, index):\\n    \\n    '''function to drop data by index'''\\n    return df.drop(df.index[index])\"}]], \"revisionId\": [[null]], \"properties\": []}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091429\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091429\"}}, \"18\": {\"id\": 18, \"state\": [4], \"command\": [{\"id\": [18], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"data = drop_data(data, missing_list1)\"}]], \"revisionId\": [[null]], \"properties\": [\"drop_data\", \"missing_list1\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091446\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091446\"}}, \"19\": {\"id\": 19, \"state\": [4], \"command\": [{\"id\": [19], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"data.shape\"}]], \"revisionId\": [[null]], \"properties\": [\"data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091463\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091463\"}}, \"20\": {\"id\": 20, \"state\": [4], \"command\": [{\"id\": [20], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"print(\\\"Number of positive classes: \\\", len(data[data['is_iceberg'] == 1.0]))\\nprint(\\\"Number of negative classes: \\\", len(data[data['is_iceberg'] == 0.0]))\"}]], \"revisionId\": [[null]], \"properties\": [\"data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091480\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091480\"}}, \"21\": {\"id\": 21, \"state\": [4], \"command\": [{\"id\": [21], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def standardise_vector(vector):\\n    '''standardise vector'''\\n    standardised_vector = (np.array(vector) - np.mean(vector)) / np.std(vector)\\n    return standardised_vector.tolist()\"}]], \"revisionId\": [[null]], \"properties\": [\"np\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091499\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091499\"}}, \"22\": {\"id\": 22, \"state\": [4], \"command\": [{\"id\": [22], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def mean_normalise_vector(vector):\\n    '''mean normalize vector'''\\n    normalised_vector = (np.array(vector) - np.mean(vector)) / (np.max(vector) - np.min(vector))\\n    return normalised_vector.tolist()\"}]], \"revisionId\": [[null]], \"properties\": [\"np\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091516\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091516\"}}, \"23\": {\"id\": 23, \"state\": [4], \"command\": [{\"id\": [23], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def min_max_scaler(vector, minimum = 0, maximum = 1):\\n    '''minmaxscaler'''\\n    X_std  = (np.array(vector) - np.min(vector)) / (np.max(vector) - np.min(vector))\\n    scaled_vector = X_std * (maximum - minimum) + minimum\\n    return scaled_vector.tolist()\"}]], \"revisionId\": [[null]], \"properties\": [\"np\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091534\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091534\"}}, \"24\": {\"id\": 24, \"state\": [4], \"command\": [{\"id\": [24], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"data['band_1'] = data['band_1'].apply(standardise_vector)\\ndata['band_2'] = data['band_2'].apply(standardise_vector)\"}]], \"revisionId\": [[null]], \"properties\": [\"data\", \"standardise_vector\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091553\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091553\"}}, \"25\": {\"id\": 25, \"state\": [4], \"command\": [{\"id\": [25], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"data.head(5)\"}]], \"revisionId\": [[null]], \"properties\": [\"data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091570\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091570\"}}, \"26\": {\"id\": 26, \"state\": [4], \"command\": [{\"id\": [26], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"band_1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in data[\\\"band_1\\\"]])\\nband_2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in data[\\\"band_2\\\"]])\"}]], \"revisionId\": [[null]], \"properties\": [\"np\", \"data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091589\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091589\"}}, \"27\": {\"id\": 27, \"state\": [4], \"command\": [{\"id\": [27], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"print(\\\"Shape of band 1 image:\\\",band_1.shape)\\nprint(\\\"Shape of band 2 image:\\\",band_2.shape)\"}]], \"revisionId\": [[null]], \"properties\": [\"band_1\", \"band_2\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091606\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091606\"}}, \"28\": {\"id\": 28, \"state\": [4], \"command\": [{\"id\": [28], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"test_data['inc_angle'] = test_data['inc_angle'].apply(lambda x: math.radians(x))\"}]], \"revisionId\": [[null]], \"properties\": [\"test_data\", \"math\", \"x\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091625\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091625\"}}, \"29\": {\"id\": 29, \"state\": [4], \"command\": [{\"id\": [29], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"test_data.inc_angle.head()\"}]], \"revisionId\": [[null]], \"properties\": [\"test_data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091643\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091643\"}}, \"30\": {\"id\": 30, \"state\": [4], \"command\": [{\"id\": [30], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"missing_list3, count3 = find_missing_data(test_data.band_1, (5625,))\\nprint(\\\"count: \\\", count3)\\nprint(\\\"missing data: \\\", missing_list3)\"}]], \"revisionId\": [[null]], \"properties\": [\"find_missing_data\", \"test_data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091660\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091660\"}}, \"31\": {\"id\": 31, \"state\": [4], \"command\": [{\"id\": [31], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"missing_list4, count4 = find_missing_data(test_data.band_2, (5625,))\\nprint(\\\"count: \\\", count4)\\nprint(\\\"missing data: \\\", missing_list4)\"}]], \"revisionId\": [[null]], \"properties\": [\"find_missing_data\", \"test_data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091677\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091677\"}}, \"32\": {\"id\": 32, \"state\": [4], \"command\": [{\"id\": [32], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"test_data['band_1'] = test_data['band_1'].apply(standardise_vector)\\ntest_data['band_2'] = test_data['band_2'].apply(standardise_vector)\"}]], \"revisionId\": [[null]], \"properties\": [\"test_data\", \"standardise_vector\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091695\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091695\"}}, \"33\": {\"id\": 33, \"state\": [4], \"command\": [{\"id\": [33], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"band_1_test = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test_data[\\\"band_1\\\"]])\\nband_2_test = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test_data[\\\"band_2\\\"]])\"}]], \"revisionId\": [[null]], \"properties\": [\"np\", \"test_data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091712\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091712\"}}, \"34\": {\"id\": 34, \"state\": [4], \"command\": [{\"id\": [34], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"print(\\\"Shape of test set band 1 image:\\\",band_1_test.shape)\\nprint(\\\"Shape of test set band 2 image:\\\",band_2_test.shape)\"}]], \"revisionId\": [[null]], \"properties\": [\"band_1_test\", \"band_2_test\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091729\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091729\"}}, \"35\": {\"id\": 35, \"state\": [4], \"command\": [{\"id\": [35], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"labels = data.is_iceberg.as_matrix()\\nangles = data.inc_angle.as_matrix()\"}]], \"revisionId\": [[null]], \"properties\": [\"data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091749\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091749\"}}, \"36\": {\"id\": 36, \"state\": [4], \"command\": [{\"id\": [36], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# randomly choosing the train and validation indices\\ntrain_indices = np.random.choice(len(labels), round(len(labels)*0.75), replace=False)\\nvalidation_indices = np.array(list(set(range(len(labels))) - set(train_indices)))\\n\\n# extract train set\\nband_1_train = band_1[train_indices]\\nband_2_train = band_2[train_indices]\\nangles_train = angles[train_indices]\\nlabels_train = labels[train_indices]\\n\\n# extract validation set\\nband_1_validation = band_1[validation_indices]\\nband_2_validation = band_2[validation_indices]\\nangles_validation = angles[validation_indices]\\nlabels_validation = labels[validation_indices]\\n\\n# extract test set\\nband_1_test = band_1_test\\nband_2_test = band_2_test\\nangles_test = test_data.inc_angle.as_matrix()\\niD = test_data.id.as_matrix()\"}]], \"revisionId\": [[null]], \"properties\": [\"np\", \"labels\", \"band_1\", \"band_2\", \"angles\", \"test_data\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091767\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091767\"}}, \"37\": {\"id\": 37, \"state\": [4], \"command\": [{\"id\": [37], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"band_1_train = band_1_train.astype(np.float32)\\nband_1_validation = band_1_validation.astype(np.float32)\\nband_1_test = band_1_test.astype(np.float32)\\nband_2_train = band_2_train.astype(np.float32)\\nband_2_validation = band_2_validation.astype(np.float32)\\nband_2_test = band_2_test.astype(np.float32)\\nangles_train = angles_train.astype(np.float32)\\nangles_validation = angles_validation.astype(np.float32)\\nangles_test = angles_test.astype(np.float32)\\nlabels_train = labels_train.astype(np.float32)\\nlabels_validation = labels_validation.astype(np.float32)\\niD = iD.astype(np.str)\"}]], \"revisionId\": [[null]], \"properties\": [\"np\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091785\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091785\"}}, \"38\": {\"id\": 38, \"state\": [4], \"command\": [{\"id\": [38], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# delete the unnecessary variables out of memory\\ndel(data, test_data, band_1, band_2)\"}]], \"revisionId\": [[null]], \"properties\": []}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091802\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091802\"}}, \"39\": {\"id\": 39, \"state\": [4], \"command\": [{\"id\": [39], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"print(\\\"Shape of band_1_train:\\\",band_1_train.shape)\\nprint(\\\"Shape of band_2_train:\\\",band_1_train.shape)\\nprint(\\\"Shape of angles_train:\\\",angles_train.shape)\\nprint(\\\"Shape of labels_train:\\\",labels_train.shape)\\nprint(\\\"Shape of band_1_validation:\\\",band_1_validation.shape)\\nprint(\\\"Shape of band_2_validation:\\\",band_2_validation.shape)\\nprint(\\\"Shape of angles_validation:\\\",angles_validation.shape)\\nprint(\\\"Shape of labels_validation:\\\",labels_validation.shape)\\nprint(\\\"Shape of band_1_test:\\\",band_1_test.shape)\\nprint(\\\"Shape of band_2_test:\\\",band_2_test.shape)\\nprint(\\\"Shape of angles_test:\\\",angles_test.shape)\\nprint(\\\"Shape of iD:\\\",iD.shape)\"}]], \"revisionId\": [[null]], \"properties\": [\"band_1_train\", \"angles_train\", \"labels_train\", \"band_1_validation\", \"band_2_validation\", \"angles_validation\", \"labels_validation\", \"band_1_test\", \"band_2_test\", \"angles_test\", \"iD\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091820\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091820\"}}, \"40\": {\"id\": 40, \"state\": [4], \"command\": [{\"id\": [40], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def rotate_image(img, angle = 20):\\n    \\n    '''a function to rotate image by a given degree'''\\n    \\n    # rotate image\\n    original = img.copy()\\n\\n    M_rotate = cv2.getRotationMatrix2D((37,37),angle,1)\\n    img_new = cv2.warpAffine(img,M_rotate,(75,75))\\n    \\n    length_row = 0\\n    length_column = 0\\n    boundary_step = 5\\n    \\n    for i in range(len(img_new)):\\n        if img_new[0,i]!=float(0.0):\\n            length_row = i\\n            break\\n    for i in range(len(img_new)):\\n        if img_new[i,0]!=float(0.0):\\n            length_column = i\\n            break\\n    \\n    # subsitute the padding from original image\\n    img_new[:length_column+boundary_step,:length_row+boundary_step] = \\\\\\n    original[:length_column+boundary_step,:length_row+boundary_step] \\n    img_new[-(length_row+boundary_step):,:length_column+boundary_step] = \\\\\\n    original[-(length_row+boundary_step):,:length_column+boundary_step]\\n    img_new[:length_row+boundary_step,-(length_column+boundary_step):] = \\\\\\n    original[:length_row+boundary_step,-(length_column+boundary_step):]\\n    img_new[-(length_column+boundary_step):,-(length_row+boundary_step):] = \\\\\\n    original[-(length_column+boundary_step):,-(length_row+boundary_step):]\\n    \\n    return img_new\"}]], \"revisionId\": [[null]], \"properties\": [\"cv2\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091841\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091841\"}}, \"41\": {\"id\": 41, \"state\": [4], \"command\": [{\"id\": [41], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def translate_horizontal(image, shift_horizontal = 5):\\n    \\n    '''a function to translate image horizontally by a shift'''\\n    \\n    # horizontally shift image\\n    img = image.copy()\\n    \\n    shift_vertical = 0; \\n    if shift_horizontal<0:\\n        image_slice = img[:,shift_horizontal:].copy()\\n    if shift_horizontal>0:\\n        image_slice = img[:,:shift_horizontal].copy()\\n    M_translate = np.float32([[1,0,shift_horizontal],[0,1,shift_vertical]])\\n    img_new = cv2.warpAffine(img,M_translate,(75,75))\\n    \\n    # subsitute the padding from original image\\n    if shift_horizontal<0:\\n        img_new[:,shift_horizontal:] = image_slice\\n    if shift_horizontal>0:\\n        img_new[:,:shift_horizontal] = image_slice\\n        \\n    return img_new.reshape(75,75).astype(np.float32)\"}]], \"revisionId\": [[null]], \"properties\": [\"np\", \"cv2\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091860\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091860\"}}, \"42\": {\"id\": 42, \"state\": [4], \"command\": [{\"id\": [42], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def translate_vertical(image, shift_vertical = 5):\\n    \\n    '''a function to translate image vertically by a shift'''\\n    \\n    # vertically shift image\\n    img = image.copy()\\n    \\n    shift_horizontal = 0;\\n    if shift_vertical<0:\\n        image_slice = img[shift_vertical:,:].copy()\\n    if shift_vertical>0:\\n        image_slice = img[:shift_vertical,:].copy()\\n    M_translate = np.float32([[1,0,shift_horizontal],[0,1,shift_vertical]])\\n    img_new = cv2.warpAffine(img,M_translate,(75,75))\\n    \\n    # subsitute the padding from original image\\n    if shift_vertical<0:\\n        img_new[shift_vertical:,:] = image_slice\\n    if shift_vertical>0:\\n        img_new[:shift_vertical,:] = image_slice\\n        \\n    return img_new.reshape(75,75).astype(np.float32)\"}]], \"revisionId\": [[null]], \"properties\": [\"np\", \"cv2\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091878\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091878\"}}, \"43\": {\"id\": 43, \"state\": [4], \"command\": [{\"id\": [43], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def translate_positive_diagonal(image, shift_diagonal = 5):\\n    \\n    '''a function to translate image along positive diagonal'''\\n    \\n    # translate image along positive diagonal\\n    img = image.copy()\\n    \\n    if shift_diagonal<0:\\n        hor_slice = img[shift_diagonal:,:].copy()\\n        ver_slice = img[:,shift_diagonal:].copy()\\n    else:\\n        hor_slice = img[:shift_diagonal,:].copy()\\n        ver_slice = img[:,:shift_diagonal].copy()\\n    M_translate = np.float32([[1,0,shift_diagonal],[0,1,shift_diagonal]])\\n    img_new = cv2.warpAffine(img,M_translate,(75,75))\\n    \\n    # subsitute the padding from original image\\n    if shift_diagonal<0:\\n        img_new[shift_diagonal:,:] = hor_slice\\n        img_new[:,shift_diagonal:] = ver_slice\\n    else:\\n        img_new[:shift_diagonal,:] = hor_slice\\n        img_new[:,:shift_diagonal] = ver_slice\\n    \\n    return img_new.reshape(75,75).astype(np.float32)\"}]], \"revisionId\": [[null]], \"properties\": [\"np\", \"cv2\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091897\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091897\"}}, \"44\": {\"id\": 44, \"state\": [4], \"command\": [{\"id\": [44], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def translate_negative_diagonal(image, shift_diagonal = 5):\\n    \\n    '''a function to translate image along negative diagonal'''\\n    \\n    # translate image along negative diagonal\\n    img = image.copy()\\n    \\n    if shift_diagonal<0:\\n        hor_slice = img[:-shift_diagonal,:].copy()\\n        ver_slice = img[:,shift_diagonal:].copy()\\n    if shift_diagonal>0:\\n        hor_slice = img[-shift_diagonal:,:].copy()\\n        ver_slice = img[:,:shift_diagonal].copy()\\n    M_translate = np.float32([[1,0,shift_diagonal],[0,1,-shift_diagonal]])\\n    img_new = cv2.warpAffine(img,M_translate,(75,75))\\n    \\n    # subsitute the padding from original image\\n    if shift_diagonal<0:\\n        img_new[:-shift_diagonal,:] = hor_slice\\n        img_new[:,shift_diagonal:] = ver_slice\\n    if shift_diagonal>0:\\n        img_new[-shift_diagonal:,:] = hor_slice\\n        img_new[:,:shift_diagonal] = ver_slice\\n        \\n    return img_new.reshape(75,75).astype(np.float32)\"}]], \"revisionId\": [[null]], \"properties\": [\"np\", \"cv2\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091917\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091917\"}}, \"45\": {\"id\": 45, \"state\": [4], \"command\": [{\"id\": [45], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def flip(image, direction = 0):\\n    \\n    '''a function to flip image'''\\n    img = image.copy()\\n    return cv2.flip(img,direction)\"}]], \"revisionId\": [[null]], \"properties\": [\"cv2\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091935\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091935\"}}, \"46\": {\"id\": 46, \"state\": [4], \"command\": [{\"id\": [46], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def zoom(image, zoom_shift = 5):\\n    \\n    '''a function to zoom image'''\\n    \\n    # zoom image\\n    img = image.copy()\\n    \\n    # zoom in \\n    if zoom_shift>0:\\n        # scale\\n        img_new = cv2.resize(img, (75+zoom_shift*2,75+zoom_shift*2)) \\n        # crop\\n        img_new = img_new[zoom_shift:-zoom_shift,zoom_shift:-zoom_shift] \\n    # zoom out\\n    else:\\n        zoom_shift *=-1\\n        \\n        hor_top = img[:zoom_shift,:]\\n        hor_bottom =img[-zoom_shift:,:]\\n        ver_left = img[:,:zoom_shift]\\n        ver_right = img[:,-zoom_shift:]\\n        \\n        # scale\\n        img_new = cv2.resize(img, (75-zoom_shift*2,75-zoom_shift*2)) \\n        # zero padding\\n        img_new = cv2.copyMakeBorder(img_new,zoom_shift,zoom_shift,zoom_shift,zoom_shift,\\n                                     cv2.BORDER_CONSTANT,value=0.0)\\n        # subsitute the padding from original image\\n        img_new[:zoom_shift,:] = hor_top\\n        img_new[-zoom_shift:,:] = hor_bottom\\n        img_new[:,:zoom_shift] = ver_left\\n        img_new[:,-zoom_shift:] = ver_right     \\n        \\n    return img_new.reshape(75,75).astype(np.float32)\"}]], \"revisionId\": [[null]], \"properties\": [\"np\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091953\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091953\"}}, \"47\": {\"id\": 47, \"state\": [4], \"command\": [{\"id\": [47], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"matplotlib.rcParams['figure.figsize'] = (20.0, 14.0)\\nimage = band_1_test[3].copy()\\nplt.subplot(3, 5, 1)\\nplt.title(\\\"Original Image\\\")\\nplt.imshow(image)\\nplt.subplot(3, 5, 2)\\ngenerated_image = rotate_image(image,40)\\nplt.title(\\\"Rotation by +ve degree\\\")\\nplt.imshow(generated_image)\\nplt.subplot(3, 5, 3)\\ngenerated_image = rotate_image(image,-40)\\nplt.title(\\\"Rotation by -ve degree\\\")\\nplt.imshow(generated_image)\\nplt.subplot(3, 5, 4)\\ngenerated_image = translate_horizontal(image,10)\\nplt.title(\\\"Horizonation translation to right\\\")\\nplt.imshow(generated_image)\\nplt.subplot(3, 5, 5)\\ngenerated_image = translate_horizontal(image,-10)\\nplt.title(\\\"Horizonation translation to left\\\")\\nplt.imshow(generated_image)\\nplt.subplot(3, 5, 6)\\ngenerated_image = translate_vertical(image,10)\\nplt.title(\\\"Vertical translation downward\\\")\\nplt.imshow(generated_image)\\nplt.subplot(3, 5, 7)\\ngenerated_image = translate_vertical(image,-10)\\nplt.title(\\\"Vertical translation upward\\\")\\nplt.imshow(generated_image)\\nplt.subplot(3, 5, 8)\\ngenerated_image = translate_positive_diagonal(image,10)\\nplt.title(\\\"SE translation\\\")\\nplt.imshow(generated_image)\\nplt.subplot(3, 5, 9)\\ngenerated_image = translate_positive_diagonal(image,-10)\\nplt.title(\\\"NW translation\\\")\\nplt.imshow(generated_image)\\nplt.subplot(3, 5, 10)\\ngenerated_image = translate_negative_diagonal(image,10)\\nplt.title(\\\"NE translation\\\")\\nplt.imshow(generated_image)\\nplt.subplot(3, 5, 11)\\ngenerated_image = translate_negative_diagonal(image,-10)\\nplt.title(\\\"SW translation\\\")\\nplt.imshow(generated_image)\\nplt.subplot(3, 5, 12)\\ngenerated_image = flip(image,0)\\nplt.title(\\\"Vertical flip\\\")\\nplt.imshow(generated_image)\\nplt.subplot(3, 5, 13)\\ngenerated_image = flip(image,1)\\nplt.title(\\\"Horizontal flip\\\")\\nplt.imshow(generated_image)\\nplt.subplot(3, 5, 14)\\ngenerated_image = zoom(image,10)\\nplt.title(\\\"Zoom in\\\")\\nplt.imshow(generated_image)\\nplt.subplot(3, 5, 15)\\ngenerated_image = zoom(image,-10)\\nplt.title(\\\"Zoom out\\\")\\nplt.imshow(generated_image)\\nplt.show()\"}]], \"revisionId\": [[null]], \"properties\": [\"matplotlib\", \"band_1_test\", \"plt\", \"rotate_image\", \"translate_horizontal\", \"translate_vertical\", \"translate_positive_diagonal\", \"translate_negative_diagonal\", \"flip\", \"zoom\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091972\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091972\"}}, \"48\": {\"id\": 48, \"state\": [4], \"command\": [{\"id\": [48], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def augment_data(band1, band2, angles, labels):\\n    \\n    '''a function to augment band1 and band2 image'''\\n    \\n    # list to store the generated data\\n    band1_generated = []\\n    band2_generated = []\\n    angles_generated = []\\n    labels_generated = []\\n    \\n    # iterate through each point in train set\\n    for i in range(labels.shape[0]):\\n        \\n        # rotate by positive degree\\n        angle = np.random.randint(5,20)\\n        band1_generated.append(rotate_image(band1[i],angle)) \\n        band2_generated.append(rotate_image(band2[i],angle))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])\\n        \\n        # rotate by negative degree\\n        angle = np.random.randint(5,20)\\n        band1_generated.append(rotate_image(band1[i],-angle)) \\n        band2_generated.append(rotate_image(band2[i],-angle))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])\\n        \\n        # positive horizontal shift\\n        shift = np.random.randint(3,7)\\n        band1_generated.append(translate_horizontal(band1[i],+shift)) \\n        band2_generated.append(translate_horizontal(band2[i],+shift))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])\\n        \\n        # negative horizontal shift\\n        shift = np.random.randint(3,7) \\n        band1_generated.append(translate_horizontal(band1[i],-shift)) \\n        band2_generated.append(translate_horizontal(band2[i],-shift))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])\\n        \\n        # positive vertical shift\\n        shift = np.random.randint(0,7)  \\n        band1_generated.append(translate_vertical(band1[i],+shift)) \\n        band2_generated.append(translate_vertical(band2[i],+shift))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])\\n        \\n        # negative vertical shift\\n        shift = np.random.randint(3,7) \\n        band1_generated.append(translate_vertical(band1[i],-shift)) \\n        band2_generated.append(translate_vertical(band2[i],-shift))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])\\n        \\n        # translate along positive diagonal in positive direction\\n        shift = np.random.randint(3,7)  \\n        band1_generated.append(translate_positive_diagonal(band1[i],+shift)) \\n        band2_generated.append(translate_positive_diagonal(band2[i],+shift))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])\\n        \\n        # translate along positive diagonal in negative direction\\n        shift = np.random.randint(3,7)  \\n        band1_generated.append(translate_positive_diagonal(band1[i],-shift)) \\n        band2_generated.append(translate_positive_diagonal(band2[i],-shift))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])\\n        \\n        # translate along negative diagonal in positive direction\\n        shift = np.random.randint(3,7)   \\n        band1_generated.append(translate_negative_diagonal(band1[i],+shift)) \\n        band2_generated.append(translate_negative_diagonal(band2[i],+shift))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])\\n        \\n        # translate along negative diagonal in negative direction\\n        shift = np.random.randint(3,7)   \\n        band1_generated.append(translate_negative_diagonal(band1[i],-shift)) \\n        band2_generated.append(translate_negative_diagonal(band2[i],-shift))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])\\n        \\n        # vertical flip\\n        band1_generated.append(flip(band1[i],0)) \\n        band2_generated.append(flip(band2[i],0))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])\\n        \\n        # horizontal flip\\n        band1_generated.append(flip(band1[i],1)) \\n        band2_generated.append(flip(band2[i],1))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])\\n        \\n        # zoom in image\\n        zoom_shift = np.random.randint(2,5)\\n        band1_generated.append(zoom(band1[i],zoom_shift)) \\n        band2_generated.append(zoom(band2[i],zoom_shift))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])\\n        \\n        # zoom out image\\n        zoom_shift = np.random.randint(2,5) \\n        band1_generated.append(zoom(band1[i],-zoom_shift)) \\n        band2_generated.append(zoom(band2[i],-zoom_shift))\\n        angles_generated.append(angles[i])\\n        labels_generated.append(labels[i])        \\n        \\n    # convert the generated data into numpy array\\n    band1_generated = np.array(band1_generated)\\n    band2_generated = np.array(band2_generated)\\n    angles_generated = np.array(angles_generated)\\n    labels_generated = np.array(labels_generated)\\n    \\n    # concatenate the generated data to original train set\\n    band1_augmented = np.concatenate((band1, band1_generated),axis=0)\\n    band2_augmented = np.concatenate((band2, band2_generated),axis=0)\\n    angles_augmented = np.concatenate((angles, angles_generated),axis=0)\\n    labels_augmented = np.concatenate((labels, labels_generated),axis=0)\\n    \\n    return band1_augmented, band2_augmented, angles_augmented, labels_augmented\"}]], \"revisionId\": [[null]], \"properties\": [\"np\", \"labels\", \"rotate_image\", \"angles\", \"translate_horizontal\", \"translate_vertical\", \"translate_positive_diagonal\", \"translate_negative_diagonal\", \"flip\", \"zoom\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.091990\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.091990\"}}, \"49\": {\"id\": 49, \"state\": [4], \"command\": [{\"id\": [49], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# augment train set\\nband_1_train, band_2_train, angles_train, labels_train = \\\\\\n    augment_data(band_1_train, band_2_train, angles_train, labels_train)\"}]], \"revisionId\": [[null]], \"properties\": [\"augment_data\", \"band_1_train\", \"band_2_train\", \"angles_train\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092051\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092051\"}}, \"50\": {\"id\": 50, \"state\": [4], \"command\": [{\"id\": [50], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"print(\\\"Shape of band_1_train:\\\",band_1_train.shape)\\nprint(\\\"Shape of band_2_train:\\\",band_2_train.shape)\\nprint(\\\"Shape of angles_train:\\\",angles_train.shape)\\nprint(\\\"Shape of labels_train:\\\",labels_train.shape)\"}]], \"revisionId\": [[null]], \"properties\": [\"band_1_train\", \"band_2_train\", \"angles_train\", \"labels_train\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092070\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092070\"}}, \"51\": {\"id\": 51, \"state\": [4], \"command\": [{\"id\": [51], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"image_train = np.concatenate([band_1_train[:, :, :, np.newaxis],\\n                             band_2_train[:, :, :, np.newaxis],\\n                             ((band_1_train+band_2_train)/2)[:, :, :, np.newaxis]],\\n                             axis=-1)\"}]], \"revisionId\": [[null]], \"properties\": [\"np\", \"band_1_train\", \"band_2_train\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092089\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092089\"}}, \"52\": {\"id\": 52, \"state\": [4], \"command\": [{\"id\": [52], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"image_validation = np.concatenate([band_1_validation[:, :, :, np.newaxis],\\n                             band_2_validation[:, :, :, np.newaxis],\\n                             ((band_1_validation+band_2_validation)/2)[:, :, :, np.newaxis]],\\n                             axis=-1)\"}]], \"revisionId\": [[null]], \"properties\": [\"np\", \"band_1_validation\", \"band_2_validation\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092106\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092106\"}}, \"53\": {\"id\": 53, \"state\": [4], \"command\": [{\"id\": [53], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"image_test = np.concatenate([band_1_test[:, :, :, np.newaxis],\\n                             band_2_test[:, :, :, np.newaxis],\\n                             ((band_1_test+band_2_test)/2)[:, :, :, np.newaxis]],\\n                             axis=-1)\"}]], \"revisionId\": [[null]], \"properties\": [\"np\", \"band_1_test\", \"band_2_test\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092123\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092123\"}}, \"54\": {\"id\": 54, \"state\": [4], \"command\": [{\"id\": [54], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# delete the unnecessary variables out of memory\\ndel(band_1_train, band_1_validation, band_1_test, band_2_train, band_2_validation, band_2_test)\"}]], \"revisionId\": [[null]], \"properties\": []}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092140\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092140\"}}, \"55\": {\"id\": 55, \"state\": [4], \"command\": [{\"id\": [55], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"print(\\\"Shape of image_train:\\\",image_train.shape)\\nprint(\\\"Shape of image_validation:\\\",image_validation.shape)\\nprint(\\\"Shape of image_test:\\\",image_test.shape)\"}]], \"revisionId\": [[null]], \"properties\": [\"image_train\", \"image_validation\", \"image_test\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092158\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092158\"}}, \"56\": {\"id\": 56, \"state\": [4], \"command\": [{\"id\": [56], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"import tensorflow as tf\\nfrom tensorflow.python.framework import ops\\nops.reset_default_graph()\\ntf.set_random_seed(tf_rand_seed)\\n# sess = tf.InteractiveSession()\"}]], \"revisionId\": [[null]], \"properties\": [\"tf_rand_seed\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092176\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092176\"}}, \"57\": {\"id\": 57, \"state\": [4], \"command\": [{\"id\": [57], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"labels_train = pd.get_dummies(labels_train).as_matrix()\\nlabels_validation = pd.get_dummies(labels_validation).as_matrix()\"}]], \"revisionId\": [[null]], \"properties\": [\"pd\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092194\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092194\"}}, \"58\": {\"id\": 58, \"state\": [4], \"command\": [{\"id\": [58], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"print(\\\"Shape of labels_train:\\\", labels_train.shape)\\nprint(\\\"Shape of labels_validation:\\\", labels_validation.shape)\"}]], \"revisionId\": [[null]], \"properties\": [\"labels_train\", \"labels_validation\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092211\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092211\"}}, \"59\": {\"id\": 59, \"state\": [4], \"command\": [{\"id\": [59], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# image dimensions\\nwidth = 75\\nheight = 75\\nnum_channels = 3\\nflat = width * height\\nnum_classes = 2\"}]], \"revisionId\": [[null]], \"properties\": []}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092229\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092229\"}}, \"60\": {\"id\": 60, \"state\": [4], \"command\": [{\"id\": [60], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"image = tf.placeholder(tf.float32, shape=[None, height, width, num_channels])\\n# angle = tf.placeholder(tf.float32, shape= [None, 1])\\ny_true = tf.placeholder(tf.int32, shape=[None, num_classes])\\nkeep_prob = tf.placeholder(tf.float32)\"}]], \"revisionId\": [[null]], \"properties\": [\"tf\", \"height\", \"width\", \"num_channels\", \"num_classes\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092247\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092247\"}}, \"61\": {\"id\": 61, \"state\": [4], \"command\": [{\"id\": [61], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def create_weights(shape):\\n    '''a function to create weight tensor'''\\n    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\\n \\ndef create_biases(size):\\n    '''a function to create bias tensor'''\\n    return tf.Variable(tf.constant(0.05, shape=[size]))\"}]], \"revisionId\": [[null]], \"properties\": [\"tf\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092265\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092265\"}}, \"62\": {\"id\": 62, \"state\": [4], \"command\": [{\"id\": [62], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def create_convolutional_layer(input,\\n                               num_input_channels,\\n                               conv_filter_size,\\n                               max_pool_filter_size,\\n                               num_filters):  \\n    \\n    '''a function to create convoutional layer'''\\n    \\n    # create filter for the convolutional layer\\n    weights = create_weights(shape=[conv_filter_size, conv_filter_size, num_input_channels, num_filters])\\n    \\n    # create biases\\n    biases = create_biases(num_filters)\\n    \\n    # create covolutional layer\\n    layer = tf.nn.conv2d(input=input,\\n                     filter=weights,\\n                     strides=[1, 1, 1, 1],\\n                     padding='SAME')\\n    \\n    # add the bias to the convolutional layer\\n    layer += biases\\n    \\n    # relu activation layer fed into layer\\n    layer = tf.nn.relu(layer)\\n    \\n    # max pooling to half the size of the image\\n    layer = tf.nn.max_pool(value=layer,\\n                            ksize=[1, max_pool_filter_size, max_pool_filter_size, 1],\\n                            strides=[1, 2, 2, 1],\\n                            padding='SAME')\\n        \\n    # return the output layer of the convolution\\n    return layer\"}]], \"revisionId\": [[null]], \"properties\": [\"create_weights\", \"create_biases\", \"tf\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092281\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092281\"}}, \"63\": {\"id\": 63, \"state\": [4], \"command\": [{\"id\": [63], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def create_flatten_layer(layer):\\n    \\n    '''a function for creating flattened layer from convolutional output'''\\n    \\n    # extract the shape of the layer\\n    layer_shape = layer.get_shape()\\n    # calculate the number features of the flattened layer\\n    num_features = layer_shape[1:4].num_elements()\\n    # create the flattened layer\\n    layer = tf.reshape(layer, [-1, num_features])\\n    # return the layer\\n    return layer\"}]], \"revisionId\": [[null]], \"properties\": [\"tf\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092298\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092298\"}}, \"64\": {\"id\": 64, \"state\": [4], \"command\": [{\"id\": [64], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"def create_fc_layer(input,          \\n                    num_inputs,    \\n                    num_outputs,\\n                    use_relu=True,\\n                    dropout = False, \\n                    keep_prob = 0.2):\\n    \\n    '''a function for creating fully connected layer'''\\n    \\n    #Let's define trainable weights and biases.\\n    weights = create_weights(shape=[num_inputs, num_outputs])\\n    biases = create_biases(num_outputs)\\n    \\n    # matrix multiplication between input and weight matrix\\n    layer = tf.matmul(input, weights) + biases\\n    \\n    # add relu activation if wanted\\n    if use_relu:\\n        layer = tf.nn.relu(layer)\\n        \\n    # if dropout is wanted add dropout\\n    if dropout:        \\n        layer = tf.nn.dropout(layer, keep_prob)\\n    \\n    # return layer\\n    return layer\"}]], \"revisionId\": [[null]], \"properties\": [\"create_weights\", \"create_biases\", \"tf\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092314\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092314\"}}, \"65\": {\"id\": 65, \"state\": [4], \"command\": [{\"id\": [65], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# paramters for 1st convolutional layer\\nconv1_features = 64\\nconv1_filter_size = 3\\nmax_pool_size1 = 2\\n\\n# paramters for 2nd convolutional layer\\nconv2_features = 128\\nconv2_filter_size = 3\\nmax_pool_size2 = 2\\n\\n# paramters for 3rd convolutional layer\\nconv3_features = 128\\nconv3_filter_size = 3\\nmax_pool_size3 = 2\\n\\n# paramters for 4th convolutional layer\\nconv4_features = 64\\nconv4_filter_size = 3\\nmax_pool_size4 = 2\\n\\n# number of featuers of 1st fully connected layer\\nfc_layer_size1 = 512\\n\\n# number of featuers of 2nd fully connected layer\\nfc_layer_size2 = 256\"}]], \"revisionId\": [[null]], \"properties\": []}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092332\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092332\"}}, \"66\": {\"id\": 66, \"state\": [4], \"command\": [{\"id\": [66], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"layer_conv1 = create_convolutional_layer(input=image,\\n                                         num_input_channels= num_channels,\\n                                         conv_filter_size = conv1_filter_size,\\n                                         max_pool_filter_size = max_pool_size1,\\n                                         num_filters = conv1_features)\\nlayer_conv1\"}]], \"revisionId\": [[null]], \"properties\": [\"create_convolutional_layer\", \"image\", \"num_channels\", \"conv1_filter_size\", \"max_pool_size1\", \"conv1_features\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092350\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092350\"}}, \"67\": {\"id\": 67, \"state\": [4], \"command\": [{\"id\": [67], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"layer_conv2 = create_convolutional_layer(input=layer_conv1,\\n                                         num_input_channels= conv1_features,\\n                                         conv_filter_size = conv2_filter_size,\\n                                         max_pool_filter_size = max_pool_size2,\\n                                         num_filters = conv2_features)\\nlayer_conv2\"}]], \"revisionId\": [[null]], \"properties\": [\"create_convolutional_layer\", \"layer_conv1\", \"conv1_features\", \"conv2_filter_size\", \"max_pool_size2\", \"conv2_features\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092368\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092368\"}}, \"68\": {\"id\": 68, \"state\": [4], \"command\": [{\"id\": [68], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"layer_conv3 = create_convolutional_layer(input=layer_conv2,\\n                                         num_input_channels= conv2_features,\\n                                         conv_filter_size = conv3_filter_size,\\n                                         max_pool_filter_size = max_pool_size3,\\n                                         num_filters = conv3_features)\\nlayer_conv3\"}]], \"revisionId\": [[null]], \"properties\": [\"create_convolutional_layer\", \"layer_conv2\", \"conv2_features\", \"conv3_filter_size\", \"max_pool_size3\", \"conv3_features\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092386\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092386\"}}, \"69\": {\"id\": 69, \"state\": [4], \"command\": [{\"id\": [69], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"layer_conv4 = create_convolutional_layer(input=layer_conv3,\\n                                         num_input_channels= conv3_features,\\n                                         conv_filter_size = conv4_filter_size,\\n                                         max_pool_filter_size = max_pool_size4,\\n                                         num_filters = conv4_features)\\nlayer_conv4\"}]], \"revisionId\": [[null]], \"properties\": [\"create_convolutional_layer\", \"layer_conv3\", \"conv3_features\", \"conv4_filter_size\", \"max_pool_size4\", \"conv4_features\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092403\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092403\"}}, \"70\": {\"id\": 70, \"state\": [4], \"command\": [{\"id\": [70], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"layer_flat = create_flatten_layer(layer_conv4)\\nlayer_flat\"}]], \"revisionId\": [[null]], \"properties\": [\"create_flatten_layer\", \"layer_conv4\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092421\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092421\"}}, \"71\": {\"id\": 71, \"state\": [4], \"command\": [{\"id\": [71], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# layer_angle = create_fc_layer(input = angle,\\n#                               num_inputs=1,\\n#                               num_outputs=1,\\n#                               use_relu= True)\"}]], \"revisionId\": [[null]], \"properties\": []}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092439\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092439\"}}, \"72\": {\"id\": 72, \"state\": [4], \"command\": [{\"id\": [72], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# combined_layer = tf.concat((layer_flat, layer_angle), axis=1)\"}]], \"revisionId\": [[null]], \"properties\": []}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092455\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092455\"}}, \"73\": {\"id\": 73, \"state\": [4], \"command\": [{\"id\": [73], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# layer_fc1 = create_fc_layer(input=combined_layer,\\n#                             num_inputs=combined_layer.get_shape()[1:4].num_elements(),\\n#                             num_outputs=fc_layer_size1,\\n#                             use_relu=True,\\n#                             dropout =True,\\n#                             keep_prob = keep_prob)\"}]], \"revisionId\": [[null]], \"properties\": []}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092472\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092472\"}}, \"74\": {\"id\": 74, \"state\": [4], \"command\": [{\"id\": [74], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"layer_fc1 = create_fc_layer(input=layer_flat,\\n                            num_inputs=layer_flat.get_shape()[1:4].num_elements(),\\n                            num_outputs=fc_layer_size1,\\n                            use_relu=True,\\n                            dropout =True,\\n                            keep_prob = keep_prob)\\nlayer_fc1\"}]], \"revisionId\": [[null]], \"properties\": [\"create_fc_layer\", \"layer_flat\", \"fc_layer_size1\", \"keep_prob\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092511\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092511\"}}, \"75\": {\"id\": 75, \"state\": [4], \"command\": [{\"id\": [75], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"layer_fc2 = create_fc_layer(input=layer_fc1,\\n                            num_inputs=fc_layer_size1,\\n                            num_outputs=fc_layer_size2,\\n                            use_relu=True,\\n                            dropout =True,\\n                            keep_prob = keep_prob)\\nlayer_fc2\"}]], \"revisionId\": [[null]], \"properties\": [\"create_fc_layer\", \"layer_fc1\", \"fc_layer_size1\", \"fc_layer_size2\", \"keep_prob\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092529\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092529\"}}, \"76\": {\"id\": 76, \"state\": [4], \"command\": [{\"id\": [76], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"output_layer = create_fc_layer(input=layer_fc2,\\n                     num_inputs = fc_layer_size2,\\n                     num_outputs = num_classes,\\n                     use_relu=False)\\noutput_layer\"}]], \"revisionId\": [[null]], \"properties\": [\"create_fc_layer\", \"layer_fc2\", \"fc_layer_size2\", \"num_classes\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092547\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092547\"}}, \"77\": {\"id\": 77, \"state\": [4], \"command\": [{\"id\": [77], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# softmax operation on the output layer\\ny_pred = tf.nn.softmax(output_layer)\\n# extract the vector of predicted class\\ny_pred_cls = tf.argmax(y_pred, axis=1, output_type=tf.int32)\\n# extract the vector of labels\\ny_true_cls = tf.argmax(y_true, axis=1, output_type=tf.int32)\"}]], \"revisionId\": [[null]], \"properties\": [\"tf\", \"output_layer\", \"y_true\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092565\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092565\"}}, \"78\": {\"id\": 78, \"state\": [4], \"command\": [{\"id\": [78], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# extract the vector of correct prediction\\ncorrect_prediction = tf.equal(y_pred_cls, y_true_cls)\\n# operation to calculate accuracy\\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\"}]], \"revisionId\": [[null]], \"properties\": [\"tf\", \"y_pred_cls\", \"y_true_cls\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092581\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092581\"}}, \"79\": {\"id\": 79, \"state\": [4], \"command\": [{\"id\": [79], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# operation to calculate cross entropy\\ncross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=output_layer,\\n                                                    labels=y_true)\\n# mean of cross entropy to act as the loss\\nloss = tf.reduce_mean(cross_entropy)\"}]], \"revisionId\": [[null]], \"properties\": [\"tf\", \"output_layer\", \"y_true\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092599\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092599\"}}, \"80\": {\"id\": 80, \"state\": [4], \"command\": [{\"id\": [80], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# sess.run(tf.global_variables_initializer())\\n# loss.eval(feed_dict={image: image_validation,\\n#                          angle: np.transpose([angles_validation]),\\n#                          y_true: labels_validation, keep_prob: 1.0})\"}]], \"revisionId\": [[null]], \"properties\": []}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092616\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092616\"}}, \"81\": {\"id\": 81, \"state\": [4], \"command\": [{\"id\": [81], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# learning rate of optimizer\\nlearning_rate = (1e-3)*0.30\\n# train step\\ntrain_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\"}]], \"revisionId\": [[null]], \"properties\": [\"tf\", \"loss\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092633\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092633\"}}, \"82\": {\"id\": 82, \"state\": [4], \"command\": [{\"id\": [82], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# lists to store the train loss, validation loss, validation accuracy at each iteration\\ntrain_loss = []\\nvalid_loss = []\\nvalid_acc = []\\n\\n# batch size\\nbatch_size = 255\\n# max iteration\\nmax_iter = 700\"}]], \"revisionId\": [[null]], \"properties\": []}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092650\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092650\"}}, \"83\": {\"id\": 83, \"state\": [4], \"command\": [{\"id\": [83], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# create a saver object\\nsaver = tf.train.Saver(max_to_keep=1)\\n\\n# variables to store the accuracy, loss, iteration of our best model\\nbest_accuracy = 0\\nbest_loss = 1000000\\nbest_iteration = None\\n\\niteration = 0\\n\\n# create a graph session and optimize under it\\nwith tf.Session() as sess:\\n    \\n    # initialize variables\\n    sess.run(tf.global_variables_initializer())\\n\\n    # while 57 minutes have not elapsed (to finish before the kernel is killed)\\n    while (time.time()-t1) < 3420:\\n        \\n        # break if max iteration is reached\\n        if iteration >= max_iter:\\n            break\\n\\n        # randomly choosing the indices of the batch \\n        rand_index = np.random.choice(labels_train.shape[0], size=batch_size)\\n\\n        # extract the batch image and labels\\n        image_rand = image_train[rand_index]\\n#         angles_rand = angles_train[rand_index]\\n        labels_rand = labels_train[rand_index]\\n\\n        # feed dictionary for batch\\n        feed_dict_batch =  {image: image_rand,\\n#                             angle: np.transpose([angles_rand]),\\n                            y_true: labels_rand,\\n                            keep_prob: 0.7}\\n        # feed dictionary for train\\n        feed_dict_train =  {image: image_rand,\\n#                             angle: np.transpose([angles_rand]),\\n                            y_true: labels_rand,\\n                            keep_prob: 1.0}\\n        # feed dictionary for validation\\n        feed_dict_validation =  {image: image_validation,\\n#                                  angle: np.transpose([angles_validation]),\\n                                 y_true: labels_validation,\\n                                 keep_prob: 1.0}\\n        \\n        # execute optimization step\\n        sess.run(train_step, feed_dict=feed_dict_batch)\\n\\n        # calculate temporary train loss and append it to the designated list\\n        temp_train_loss = loss.eval(session=sess, feed_dict=feed_dict_train)\\n        train_loss.append(temp_train_loss)\\n        # calculate temporary validation loss and append it to the designated list\\n        temp_validation_loss = loss.eval(session=sess, feed_dict=feed_dict_validation)\\n        valid_loss.append(temp_validation_loss)\\n        # calculate temporary validation accuracy and append it to the designated list\\n        temp_validation_accuracy = accuracy.eval(session=sess, feed_dict=feed_dict_validation)\\n        valid_acc.append(temp_validation_accuracy)\\n\\n        # if the valid loss is tied with best recorded so far but valid acc is better then\\n        # update the parameters of the best model and save the model\\n        if (temp_validation_loss == best_loss) and (temp_validation_accuracy > best_accuracy):\\n            best_accuracy = temp_validation_accuracy\\n            best_loss = temp_validation_loss\\n            best_iteration = iteration           \\n            saver.save(sess, './my-model', global_step = best_iteration)\\n        \\n        # if valid accuracy is better than best recorded so far then update the best valid accuracy\\n        if temp_validation_accuracy > best_accuracy:\\n            best_accuracy = temp_validation_accuracy\\n        \\n        # if valid loss is better than best recorded so far then\\n        # update the parameters of the best model and save the model\\n        if temp_validation_loss < best_loss:\\n            best_loss = temp_validation_loss\\n            best_iteration = iteration          \\n            saver.save(sess, './my-model', global_step = best_iteration)\\n\\n        # print metric info\\n        print(\\\"iterations:\\\",iteration,\\n              \\\"| train_loss:\\\", temp_train_loss,\\n              \\\"| validation_loss:\\\", temp_validation_loss,\\n              \\\"| valid_accuracy:\\\", temp_validation_accuracy)\\n        \\n        # increment iteration\\n        iteration = iteration+1\"}]], \"revisionId\": [[null]], \"properties\": [\"tf\", \"time\", \"t1\", \"max_iter\", \"np\", \"labels_train\", \"batch_size\", \"image_train\", \"image\", \"y_true\", \"keep_prob\", \"image_validation\", \"labels_validation\", \"train_step\", \"loss\", \"train_loss\", \"valid_loss\", \"accuracy\", \"valid_acc\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092668\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092668\"}}, \"84\": {\"id\": 84, \"state\": [4], \"command\": [{\"id\": [84], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# delete unnecessary variables out of memory\\ndel(image_train, image_validation, angles_train, angles_validation, labels_train, labels_validation)\"}]], \"revisionId\": [[null]], \"properties\": []}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092685\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092685\"}}, \"85\": {\"id\": 85, \"state\": [4], \"command\": [{\"id\": [85], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"# t5 = time.time()\\n\\nwith tf.Session() as sess:    \\n    \\n    # restore the best model\\n    model_path = \\\"./\\\"+\\\"my-model-\\\"+str(best_iteration)\\n    saver.restore(sess, model_path)\\n    \\n    # break the test set into k folds other wise kernel will be out of memory\\n    n = len(iD)\\n    k = 12\\n    step = n//k\\n    \\n    # array to store the prediction\\n    preds = np.array([])\\n\\n    # iterate through each fold\\n    for i in range(k):\\n\\n        # start and end indices of the fold\\n        start = (step*i)\\n        end = (step*(i+1)) \\n    \\n        # feed dictionary for the fold\\n        feed_dict_test =  {image: image_test[start:end],\\n#                            angle: np.transpose([angles_test[start:end]]),\\n                           keep_prob: 1.0}\\n\\n        # evaluate predictions of the fold\\n        fold_preds = y_pred.eval(session=sess, feed_dict = feed_dict_test)[:,1]\\n        # append the predictions of the fold to the designated array\\n        preds = np.append(preds, fold_preds)\\n    \\n    # save the submission csv file\\n    submission_path = \\\"./submission.csv\\\"\\n    submission = pd.DataFrame({\\\"id\\\": iD, \\\"is_iceberg\\\": preds})\\n    submission.to_csv(submission_path, header = True, index=False)\\n    \\n    # save the csv file containing performance metrics of the best model \\n    results = pd.DataFrame([int(best_iteration),train_loss[best_iteration],\\n                            valid_loss[best_iteration], valid_acc[best_iteration]],\\n                           index=[\\\"iteration\\\", \\\"train loss\\\", \\\"valid loss\\\", \\\"accuracy\\\"],\\n                           columns = [\\\"results\\\"])    \\n    results_path = \\\"./results.csv\\\"    \\n    results.to_csv(results_path, header = True, index=True)\\n    \\n# t6 = time.time()\\n# print(\\\"time take for prediction: \\\", t6-t5)\"}]], \"revisionId\": [[null]], \"properties\": [\"tf\", \"best_iteration\", \"saver\", \"iD\", \"np\", \"pd\", \"train_loss\", \"valid_loss\", \"valid_acc\", \"image\", \"image_test\", \"keep_prob\", \"y_pred\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092703\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092703\"}}, \"86\": {\"id\": 86, \"state\": [4], \"command\": [{\"id\": [86], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"plt.figure(figsize=(16, 8), dpi= 80, facecolor='w', edgecolor='k')\\niterations = list(range(1,iteration+1))\\nplt.plot(iterations, train_loss, label = \\\"train loss\\\")\\nplt.plot(iterations, valid_loss, label = \\\"valid loss\\\")\\nplt.title(\\\"Loss\\\")\\nplt.xlabel(\\\"iter\\\")\\nplt.ylabel(\\\"loss\\\")\\nplt.legend()\\nplt.grid()\\nplt.show()\"}]], \"revisionId\": [[null]], \"properties\": [\"plt\", \"iteration\", \"train_loss\", \"valid_loss\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092722\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092722\"}}, \"87\": {\"id\": 87, \"state\": [4], \"command\": [{\"id\": [87], \"packageId\": [[\"script\"]], \"commandId\": [[\"python\"]], \"arguments\": [[{\"source\": \"plt.figure(figsize=(16, 8), dpi= 80, facecolor='w', edgecolor='k')\\nplt.plot(iterations, valid_acc, label = \\\"train loss\\\")\\nplt.title(\\\"Accuracy\\\")\\nplt.xlabel(\\\"iter\\\")\\nplt.ylabel(\\\"accuracy\\\")\\nplt.grid()\\nplt.show()\"}]], \"revisionId\": [[null]], \"properties\": [\"plt\", \"iterations\", \"valid_acc\"]}], \"text\": [null], \"timestamps\": {\"createdAt\": \"2021-09-17 19:30:36.092741\", \"startedAt\": null, \"finishedAt\": null, \"lastModifiedAt\": \"2021-09-17 19:30:36.092741\"}}}}}}}], \"createdAt\": [\"2021-09-17 19:30:36.092741\"], \"lastModifiedAt\": \"2021-09-17 19:30:36.092741\"}"